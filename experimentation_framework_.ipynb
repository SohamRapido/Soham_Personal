{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize all the necessary library\n",
    "from asyncio import protocols\n",
    "import pandas as pd\n",
    "from pyhive import presto\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from scipy import stats\n",
    "\n",
    "presto_host = 'bi-presto.serving.data.production.internal'\n",
    "presto_port = '80'\n",
    "presto_conn = presto.connect(\n",
    "    host=presto_host,\n",
    "    port=presto_port,\n",
    "    username='dharmendra.k@rapido.bike',\n",
    "    protocol='http',\n",
    "    catalog='hive',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions to pull metrics/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': 'ready_for_ride',\n",
       " '3': 'order_receiving',\n",
       " '6': 'on_the_way',\n",
       " '7': 'arrived',\n",
       " '8': 'started',\n",
       " '10': 'reached'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_start_end_date_from_week(week_num, year):\n",
    "\n",
    "    yyyy_wk_num = str(year) + '-W' + str(week_num)\n",
    "    # -1 and - % w pattern tells the parser to pick the Monday in that week\n",
    "    wk_start = pd.to_datetime(yyyy_wk_num + '-1', format=\"%Y-W%W-%w\")\n",
    "    wk_end = wk_start + pd.to_timedelta('6 D')\n",
    "\n",
    "    return wk_start.strftime('%Y-%m-%d'), wk_end.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def get_captain_completed_rides(single_date, city, conn_details):\n",
    "\n",
    "    query = \"\"\"\n",
    "        select \n",
    "            city_name, order_date,\n",
    "            captain_id,\n",
    "            count(order_id) as dropped_order,\n",
    "            count(case when hhmmss >= '070000' and hhmmss < '120000' then order_id end) as morning_order,\n",
    "            count(case when hhmmss >= '120000' and hhmmss < '170000' then order_id end) as afternoon_order,\n",
    "            count(case when hhmmss >= '170000' and hhmmss <= '235959' then order_id end) as evening_night_order,\n",
    "            count(case when hhmmss >= '000000' and hhmmss < '070000' then order_id end) as mid_night_order\n",
    "        from orders.order_logs_snapshot\n",
    "        where yyyymmdd = date_format(date('{start_date}'), '%Y%m%d')\n",
    "        and city_name = '{city}'\n",
    "        and service_obj_service_name = 'Link'\n",
    "        and order_status = 'dropped'\n",
    "        and (spd_fraud_flag = false or spd_fraud_flag is null)\n",
    "        group by 1, 2, 3\n",
    "    \"\"\".format(start_date=single_date, city=city)\n",
    "\n",
    "    captain_agg_order_df = pd.read_sql_query(query, conn_details)\n",
    "\n",
    "    return captain_agg_order_df\n",
    "\n",
    "\n",
    "\n",
    "def get_daily_weekly_incentive_details(start_date, end_date, city, conn_details):\n",
    "\n",
    "    query = \"\"\"\n",
    "        with \n",
    "            incentive_tbl as(\n",
    "                select\n",
    "                    incentive_id, \n",
    "                    --cities,\n",
    "                    incentivetype,\n",
    "                    startdate, enddate\n",
    "                from(\n",
    "                    select\n",
    "                        _id as incentive_id, \n",
    "                        --cities[1] as city,\n",
    "                        incentivetype,\n",
    "                        startdate, enddate,\n",
    "                        row_number() over(partition by _id order by updated_epoch desc) as row\n",
    "                    from raw.mongodb_rapidopayroll_incentives_immutable\n",
    "                    where yyyymmdd >= date_format(date_trunc('week', date('{start_date}')) - interval '2' day, '%Y%m%d')\n",
    "                    and yyyymmdd <= date_format(date('{end_date}'), '%Y%m%d')\n",
    "                    and json_array_contains(cities, '{city_name}')\n",
    "                    and json_array_contains(servicenames, 'Link')\n",
    "                    and incentivetype in ('Daily', 'Weekly Fixed')\n",
    "                    )\n",
    "                where row=1\n",
    "                and startdate >= '{start_date}'\n",
    "                and enddate <= '{end_date}'\n",
    "            )\n",
    "            \n",
    "        select \n",
    "            yyyymmdd, startdate, riderid,\n",
    "            sum(case when incentivetype = 'Daily' then incentive_amt end) as daily_incentive_amt,\n",
    "            sum(case when incentivetype = 'Weekly Fixed' then incentive_amt end) as weekly_incentive_amt\n",
    "        from(\n",
    "            select \n",
    "                riderid, yyyymmdd,\n",
    "                incentive_id, incentive_amt\n",
    "            from(\n",
    "                select riderid, yyyymmdd,\n",
    "                    tincentiveIdl as incentive_id,\n",
    "                    cast(amount as double) as incentive_amt,\n",
    "                    row_number() over(partition by _id order by updated_epoch desc) as row\n",
    "                from raw.mongodb_rapidopayroll_riderspaymentnew_immutable\n",
    "                where yyyymmdd >= date_format(date('{start_date}'), '%Y%m%d')\n",
    "                and yyyymmdd <= date_format(date('{end_date}') + interval '1' day, '%Y%m%d')\n",
    "                and transactiontype = 'specialIncentive'\n",
    "                and status = 'success' \n",
    "                and city = '{city_name}'\n",
    "                )\n",
    "            where row = 1\n",
    "            ) as rpn_tbl\n",
    "        inner join incentive_tbl on rpn_tbl.incentive_id = incentive_tbl.incentive_id\n",
    "        group by 1, 2, 3\n",
    "    \"\"\".format(start_date=start_date, end_date=end_date, city_name=city)\n",
    "\n",
    "    print(query)\n",
    "\n",
    "    incentive_df = pd.read_sql_query(query, conn_details)\n",
    "\n",
    "    return incentive_df\n",
    "\n",
    "\n",
    "def get_captain_daily_login_hrs(date, city, conn_details):\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "            userid as captain_id,\n",
    "            date_format(date_parse(yyyymmdd, '%Y%m%d'), '%Y-%m-%d') AS logindate,\n",
    "            cast(sum(duration) as double) / 3600000.0 as login_hours,\n",
    "            SUM(\n",
    "                CASE WHEN quarter_hour >= '0600' and quarter_hour <= '1159'\n",
    "                then cast(duration as double) / 3600000.0 ELSE 0 END\n",
    "            ) AS morning_duration,\n",
    "            SUM(\n",
    "                CASE WHEN quarter_hour >= '1200' and quarter_hour <= '1759'\n",
    "                then cast(duration as double) / 3600000.0 ELSE 0 END\n",
    "            ) AS afternoon_duration,\n",
    "            SUM(\n",
    "                CASE WHEN quarter_hour >= '1800' and quarter_hour <= '2359'\n",
    "                then cast(duration as double) / 3600000.0 ELSE 0 END\n",
    "            ) AS evening_duration\n",
    "        from hive.datasets.captain_login_hours\n",
    "        where yyyymmdd = date_format(date('{start_date}'), '%Y%m%d')\n",
    "        and status in ('2', '3', '6', '7', '8', '10')\n",
    "        and userid in (\n",
    "            select captainId from datasets.captain_single_view\n",
    "            where registeredcity=lower('{city}')\n",
    "            and activationdate is not null\n",
    "        )\n",
    "        GROUP BY 1, 2\n",
    "    \"\"\".format(start_date=date, city=city)\n",
    "\n",
    "    # print(query)\n",
    "\n",
    "    login_hrs_df = pd.read_sql_query(query, conn_details)\n",
    "\n",
    "    return login_hrs_df\n",
    "\n",
    "\n",
    "def get_incentive_performance(start_date, end_date, city, presto_conn):\n",
    "\n",
    "    query = \"\"\"\n",
    "        with\n",
    "            city_tbl as(\n",
    "                select displayname as city\n",
    "                from legacy.cities\n",
    "                where 1=1\n",
    "                and displayname = '{city}'\n",
    "            )\n",
    "            ,\n",
    "\n",
    "            incentive_creation_tbl as(\n",
    "                select\n",
    "                    incentivetype, incentivename, incentive_id, cities, servicenames, startdate, enddate, uuid,\n",
    "                    transform(time_slot, x -> cast(json_extract(x, '$.fromTime') as varchar)) as fromTime,\n",
    "                    transform(time_slot, x -> cast(json_extract(x, '$.toTime') as varchar)) as toTime,\n",
    "                    transform(rules, x -> cast(json_extract(x, '$.index') as double)) as slabs,\n",
    "                    transform(rules, x -> cast(json_extract(x, '$.order') as double)) as slab_order_target,\n",
    "                    transform(rules, x -> cast(json_extract(x, '$.amount') as double)) as slab_amount\n",
    "                from\n",
    "                    (\n",
    "                    select incentivename, incentive_id, cities, servicenames, incentivetype,\n",
    "                    startdate, enddate,\n",
    "                    cast(json_extract(goals, '$.rules') as array<json>) as rules,\n",
    "                    cast(json_extract(goals, '$.timeSlot') as array<json>) as time_slot,\n",
    "                    cast(json_extract(goals, '$.uuid') as varchar) as uuid\n",
    "                    from(\n",
    "                        select\n",
    "                            incentivename, _id as incentive_id, cities, servicenames, incentivetype,\n",
    "                            startdate, enddate,\n",
    "                            element_at(map_values(cast(cast(goals as json) as map(varchar, array(json)))), 1)[1] as goals,\n",
    "                            row_number() over(partition by _id order by updated_epoch) as row\n",
    "                        from raw.mongodb_rapidopayroll_incentives_immutable\n",
    "                        where yyyymmdd >= date_format(date_trunc('week', date('{start_date}')) - interval '2' day, '%Y%m%d')\n",
    "                        and yyyymmdd <= date_format(date('{end_date}'), '%Y%m%d')\n",
    "                        and startdate >= date_format(date('{start_date}'), '%Y-%m-%d')\n",
    "                        and enddate <= date_format(date('{end_date}'), '%Y-%m-%d')\n",
    "                        and json_array_contains(cities, (select city from city_tbl))\n",
    "                        -- and incentivetype = 'Weekly Fixed'\n",
    "                        and (incentivetype = 'Daily' or incentivetype = 'Weekly Fixed')\n",
    "                        )\n",
    "                    where row = 1\n",
    "                )\n",
    "            )\n",
    "\n",
    "        -- select\n",
    "        --    riderid, startdate, enddate,\n",
    "        --    slab_order_target,\n",
    "        --    slab_amount, is_set_started,\n",
    "        --    is_rule_started, is_rule_completed\n",
    "        --    order_target, order_amount,\n",
    "        --    rule_started, rule_completed\n",
    "        --from(\n",
    "            select\n",
    "                incentivetype, incentivename, incentiveid,\n",
    "                riderid, startdate, enddate,\n",
    "                fromTime, toTime,\n",
    "                slab_order_target, slab_amount, is_set_started,\n",
    "                uuid, transform(rules_status, x-> cast(json_extract(x, '$.isRuleStarted') as boolean)) as is_rule_started,\n",
    "                transform(rules_status, x-> cast(json_extract(x, '$.isRuleCompleted') as boolean)) as is_rule_completed\n",
    "            from(\n",
    "                select\n",
    "                    incentivetype, incentivename, incentiveid, riderid,\n",
    "                    startdate, enddate,\n",
    "                    slab_order_target, slab_amount,\n",
    "                    fromTime, toTime,\n",
    "                    transform(field_status, x -> json_extract(x, '$.isSetStarted')) as is_set_started,\n",
    "                    transform(field_status, x -> json_extract(x, '$.uuid')) as uuid,\n",
    "                    cast(cast(transform(field_status, x -> json_extract(x, '$.rulesStatus')) as array<json>)[1] as array<json>) as rules_status\n",
    "                from(\n",
    "                    select\n",
    "                        incentivetype, incentivename, incentiveid, riderid,\n",
    "                        slab_order_target, slab_amount,\n",
    "                        startdate, enddate,\n",
    "                        fromTime, toTime,\n",
    "                        cast(\n",
    "                            transform(cast(incentiveProgress_json as array<json>),\n",
    "                            x-> json_extract(x, '$.fieldStatus'))[1] as array<json>\n",
    "                            ) as field_status\n",
    "                    from raw.mongodb_rapidopayroll_incentive_riders_snapshot as incentive_progress_tbl\n",
    "                    inner join incentive_creation_tbl on incentive_progress_tbl.incentiveid = incentive_creation_tbl.incentive_id\n",
    "                    where yyyymmdd >= date_format(date('{start_date}') - interval '1' day, '%Y%m%d')\n",
    "                    and yyyymmdd <= date_format(date('{end_date}') + interval '1' day, '%Y%m%d')\n",
    "                )\n",
    "            )\n",
    "        --)\n",
    "        -- cross join unnest(slab_order_target, slab_amount, is_rule_started, is_rule_completed) as tbl1(order_target, order_amount, rule_started, rule_completed)\n",
    "    \"\"\".format(start_date=start_date, end_date=end_date, city=city)\n",
    "\n",
    "    rider_incentive_df = pd.read_sql_query(query, presto_conn)\n",
    "\n",
    "    return(rider_incentive_df)\n",
    "\n",
    "\n",
    "\n",
    "# def get_rider_\n",
    "\n",
    "login_hrs_state = dict(\n",
    "    zip(\n",
    "        ['2', '3', '6', '7', '8', '10'],\n",
    "        ['ready_for_ride', 'order_receiving',\n",
    "         'on_the_way', 'arrived', 'started', 'reached']\n",
    "    )\n",
    ")\n",
    "\n",
    "login_hrs_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City \t\t\t: Mumbai\n",
      "Week Start Date \t: ['2022-06-06']\n",
      "Week End Date: \t: ['2022-06-12']\n",
      "Date List \t\t: ['2022-06-06', '2022-06-07', '2022-06-08', '2022-06-09', '2022-06-10', '2022-06-11', '2022-06-12']\n",
      "required dataset :\n",
      "\n",
      "Mumbai_captain_rides_df_wk_23.csv\n",
      "Mumbai_captain_login_hrs_df_wk_23.csv\n",
      "Mumbai_captain_incentive_df_wk_23.csv\n",
      "Mumbai_Daily_incentive_progress_df_wk_23.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "city = 'Mumbai'\n",
    "week_num = 23\n",
    "year = 2022\n",
    "\n",
    "incentive_type = 'Daily'\n",
    "\n",
    "start_date, end_date = get_start_end_date_from_week(week_num, year)\n",
    "start_date = pd.to_datetime(start_date)\n",
    "end_date = pd.to_datetime(end_date)\n",
    "\n",
    "daily_list = [\n",
    "    start_date + pd.to_timedelta('{} D'.format(val))\n",
    "    for val in range(0, (end_date - start_date).days + 1, 1)\n",
    "]\n",
    "daily_list = [date.strftime('%Y-%m-%d') for date in daily_list]\n",
    "\n",
    "perf_wk = '{:02d}'.format(week_num)\n",
    "start_date = [start_date.strftime('%Y-%m-%d')]\n",
    "end_date = [end_date.strftime('%Y-%m-%d')]\n",
    "\n",
    "\n",
    "print('City \\t\\t\\t:', city)\n",
    "print('Week Start Date \\t:', start_date)\n",
    "print('Week End Date: \\t:', end_date)\n",
    "print('Date List \\t\\t:', daily_list)\n",
    "\n",
    "\n",
    "rides_file_name = '{city}_captain_rides_df_wk_{week_num}.csv'.format(\n",
    "    city=city, week_num=perf_wk\n",
    ")\n",
    "\n",
    "login_hrs_file_name = '{city}_captain_login_hrs_df_wk_{week_num}.csv'.format(\n",
    "    city=city, week_num=perf_wk\n",
    ")\n",
    "\n",
    "incentive_file_name = '{city}_captain_incentive_df_wk_{week_num}.csv'.format(\n",
    "    city=city, week_num=perf_wk\n",
    ")\n",
    "\n",
    "incentive_progress_file_name = (\n",
    "    \"{city}_{incentive_type}_incentive_progress_df_wk_{week_num}.pkl\"\n",
    "    .format(\n",
    "        city=city, incentive_type=incentive_type,\n",
    "        week_num='{:02}'.format(week_num)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    'required dataset :\\n',\n",
    "    rides_file_name,\n",
    "    login_hrs_file_name,\n",
    "    incentive_file_name,\n",
    "    incentive_progress_file_name,\n",
    "    sep='\\n'\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pull data and store it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  city_name  order_date                captain_id  dropped_order  \\\n",
      "0    Mumbai  2022-06-06  612c7eb334b93de406358227              2   \n",
      "1    Mumbai  2022-06-06  610a46c780f61d07762cc5d4             20   \n",
      "2    Mumbai  2022-06-06  62971adfa81bc548e659e1f4             11   \n",
      "3    Mumbai  2022-06-06  5e728b45f49633436e2fa906              6   \n",
      "4    Mumbai  2022-06-06  6234b3da6b6b643417706f1b             10   \n",
      "\n",
      "   morning_order  afternoon_order  evening_night_order  mid_night_order  \n",
      "0              0                0                    0                2  \n",
      "1              0                7                    8                5  \n",
      "2              2                3                    3                3  \n",
      "3              0                4                    2                0  \n",
      "4              0                4                    5                1   \n",
      "\n",
      "                 captain_id   logindate  login_hours  morning_duration  \\\n",
      "0  615d3aa72e6fe8afb2b5eb27  2022-06-06     8.521111          0.458611   \n",
      "1  61df9e46d80f2b3c4fa63329  2022-06-06     6.792500          4.300278   \n",
      "2  626169399a11654f1f688a3f  2022-06-06     0.089722          0.000000   \n",
      "3  6283674dcf1a8628240bc175  2022-06-06     1.981111          0.000000   \n",
      "4  6001303f58923915ecbaba6e  2022-06-06    11.156667          3.656944   \n",
      "\n",
      "   afternoon_duration  evening_duration  \n",
      "0            2.854722          3.698889  \n",
      "1            1.060556          1.431667  \n",
      "2            0.000000          0.089722  \n",
      "3            0.000000          1.981111  \n",
      "4            4.366389          3.046667   \n",
      "\n",
      "   yyyymmdd   startdate                   riderid  daily_incentive_amt  \\\n",
      "0  20220607  2022-06-06  628f84e664ce2b15f1ee4707                 30.0   \n",
      "1  20220606  2022-06-06  62867686b5c8522eb3ae4ae1                 70.0   \n",
      "2  20220608  2022-06-06  624d8994f73d4c0bc4cb00b9                 70.0   \n",
      "3  20220608  2022-06-06  6003ca7a2610d72d4b089d1b                200.0   \n",
      "4  20220607  2022-06-06  619cf019202c5abfdda0db13                 80.0   \n",
      "\n",
      "   weekly_incentive_amt  \n",
      "0                   NaN  \n",
      "1                   NaN  \n",
      "2                   NaN  \n",
      "3                 330.0  \n",
      "4                   NaN   \n",
      "\n",
      "  incentivename               incentiveid                   riderid  \\\n",
      "0         W23ZT  629babb3c8f87d556ae08b96  621b4b15f0b26bd7555c1e4a   \n",
      "1         W23ZT  629babb3c8f87d556ae08b96  61f750b02128ba1c17e389a7   \n",
      "2         W23ZT  629babb3c8f87d556ae08b96  621c92ba69d1ff5665d10d82   \n",
      "3         W23ZT  629babb3c8f87d556ae08b96  61f79fba6916b87e45afce4d   \n",
      "4         W23ZT  629babb3c8f87d556ae08b96  621cb72ef0b26bd96d5d3695   \n",
      "\n",
      "    startdate     enddate                       slab_order_target  \\\n",
      "0  2022-06-06  2022-06-12  [1.0, 3.0, 5.0, 8.0, 10.0, 15.0, 20.0]   \n",
      "1  2022-06-06  2022-06-12  [1.0, 3.0, 5.0, 8.0, 10.0, 15.0, 20.0]   \n",
      "2  2022-06-06  2022-06-12  [1.0, 3.0, 5.0, 8.0, 10.0, 15.0, 20.0]   \n",
      "3  2022-06-06  2022-06-12  [1.0, 3.0, 5.0, 8.0, 10.0, 15.0, 20.0]   \n",
      "4  2022-06-06  2022-06-12  [1.0, 3.0, 5.0, 8.0, 10.0, 15.0, 20.0]   \n",
      "\n",
      "                                    slab_amount is_set_started  \\\n",
      "0  [20.0, 40.0, 40.0, 60.0, 40.0, 150.0, 150.0]        [false]   \n",
      "1  [20.0, 40.0, 40.0, 60.0, 40.0, 150.0, 150.0]        [false]   \n",
      "2  [20.0, 40.0, 40.0, 60.0, 40.0, 150.0, 150.0]        [false]   \n",
      "3  [20.0, 40.0, 40.0, 60.0, 40.0, 150.0, 150.0]        [false]   \n",
      "4  [20.0, 40.0, 40.0, 60.0, 40.0, 150.0, 150.0]        [false]   \n",
      "\n",
      "                                       uuid  \\\n",
      "0  [\"1853000a-a8e0-4761-9d93-9c2ef0e415a5\"]   \n",
      "1  [\"1853000a-a8e0-4761-9d93-9c2ef0e415a5\"]   \n",
      "2  [\"1853000a-a8e0-4761-9d93-9c2ef0e415a5\"]   \n",
      "3  [\"1853000a-a8e0-4761-9d93-9c2ef0e415a5\"]   \n",
      "4  [\"1853000a-a8e0-4761-9d93-9c2ef0e415a5\"]   \n",
      "\n",
      "                                     is_rule_started  \\\n",
      "0  [False, False, False, False, False, False, False]   \n",
      "1  [False, False, False, False, False, False, False]   \n",
      "2  [False, False, False, False, False, False, False]   \n",
      "3  [False, False, False, False, False, False, False]   \n",
      "4  [False, False, False, False, False, False, False]   \n",
      "\n",
      "                                   is_rule_completed  \n",
      "0  [False, False, False, False, False, False, False]  \n",
      "1  [False, False, False, False, False, False, False]  \n",
      "2  [False, False, False, False, False, False, False]  \n",
      "3  [False, False, False, False, False, False, False]  \n",
      "4  [False, False, False, False, False, False, False]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not(os.path.exists(rides_file_name)):\n",
    "    captain_rides_df = pd.DataFrame()\n",
    "    for date in daily_list:\n",
    "        temp_rides_df = get_captain_completed_rides(date, city, presto_conn)\n",
    "        captain_rides_df = pd.concat([captain_rides_df, temp_rides_df])\n",
    "        print(\n",
    "            \"{city} Fetched captain agg daily rides as of {date} and total captains is {count}\"\n",
    "            .format(city=city, date=date, count=temp_rides_df.shape[0])\n",
    "        )\n",
    "\n",
    "    captain_rides_df.to_csv(\n",
    "        rides_file_name,\n",
    "        index=False\n",
    "    )\n",
    "    print(captain_rides_df.head(), '\\n')\n",
    "else:\n",
    "    # read the captain daily rides dataframe from local\n",
    "    captain_rides_df = pd.read_csv(rides_file_name)\n",
    "    print(captain_rides_df.head(), '\\n')\n",
    "\n",
    "\n",
    "if not(os.path.exists(login_hrs_file_name)):\n",
    "\n",
    "    captain_login_hrs_df = pd.DataFrame()\n",
    "\n",
    "    for date in daily_list:\n",
    "        temp_login_hrs_df = get_captain_daily_login_hrs(\n",
    "            date, city, presto_conn)\n",
    "        captain_login_hrs_df = pd.concat(\n",
    "            [captain_login_hrs_df, temp_login_hrs_df])\n",
    "        print('{} Fetched captain login hours for {} and total captains is {}'.format(\n",
    "            city, date, temp_login_hrs_df.shape[0]))\n",
    "\n",
    "    print('captain login hours dataframe to be saved as ', login_hrs_file_name)\n",
    "\n",
    "    captain_login_hrs_df.to_csv(\n",
    "        login_hrs_file_name,\n",
    "        index=False\n",
    "    )\n",
    "    print(captain_login_hrs_df.head(), '\\n')\n",
    "else:\n",
    "    captain_login_hrs_df = pd.read_csv(login_hrs_file_name)\n",
    "    print(captain_login_hrs_df.head(), '\\n')\n",
    "\n",
    "\n",
    "if not(os.path.exists(incentive_file_name)):\n",
    "    incentive_amt_df = pd.DataFrame()\n",
    "    for start, end in zip(start_date, end_date):\n",
    "        temp_incentive_df = get_daily_weekly_incentive_details(\n",
    "            start, end, city, presto_conn)\n",
    "        incentive_amt_df = pd.concat([incentive_amt_df, temp_incentive_df])\n",
    "        print(\"{city} Fetched captain incentive amount for the period {start} to {end}\".format(\n",
    "            city=city, start=start, end=end))\n",
    "\n",
    "    incentive_amt_df.to_csv(\n",
    "        incentive_file_name,\n",
    "        index=False\n",
    "    )\n",
    "    print(incentive_amt_df.head(), '\\n')\n",
    "else:\n",
    "    # read the incentive achievement\n",
    "    incentive_amt_df = pd.read_csv(incentive_file_name)\n",
    "    print(incentive_amt_df.head(), '\\n')\n",
    "\n",
    "incentive_amt_df['yyyymmdd'] = pd.to_datetime(incentive_amt_df['yyyymmdd'], format='%Y%m%d')\n",
    "\n",
    "if os.path.exists(incentive_progress_file_name):\n",
    "    rider_incentive_progress_df = pd.read_pickle(incentive_progress_file_name)\n",
    "    print(rider_incentive_progress_df.head())\n",
    "else:\n",
    "    print('Incentive Progress file does not exits for week {}'.format(perf_wk))\n",
    "\n",
    "# incentive progress part\n",
    "# if not (os.path.exists(incentive_progress_file_name)):\n",
    "\n",
    "#     rider_incentive_progress_df = get_incentive_performance(\n",
    "#         start_date[0], end_date[0], city, presto_conn\n",
    "#     )\n",
    "#     # save the file locally\n",
    "#     rider_incentive_progress_df.to_pickle(incentive_progress_file_name)\n",
    "#     print(rider_incentive_progress_df.head())\n",
    "# else:\n",
    "#     rider_incentive_progress_df = pd.read_pickle(incentive_progress_file_name)\n",
    "#     print(rider_incentive_progress_df.head())\n",
    "\n",
    "\n",
    "# rider_incentive_progress_df['slab'] = (\n",
    "#     rider_incentive_progress_df['slab_order_target']\n",
    "#     .apply(lambda x: list(range(1, len(x) + 1)))\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# captain_rides_df = captain_rides_df[\n",
    "#     captain_rides_df['order_date'] != '2022-06-08'\n",
    "# ]\n",
    "# captain_login_hrs_df = captain_login_hrs_df[\n",
    "#     captain_login_hrs_df['logindate'] != '2022-06-08'\n",
    "# ]\n",
    "\n",
    "\n",
    "# for date in daily_list[2:3]:\n",
    "#     temp_rides_df = get_captain_completed_rides(date, city, presto_conn)\n",
    "#     captain_rides_df = pd.concat([captain_rides_df, temp_rides_df])\n",
    "#     print(\n",
    "#         \"{city} Fetched captain agg daily rides as of {date} and total captains is {count}\"\n",
    "#         .format(city=city, date=date, count=temp_rides_df.shape[0])\n",
    "#     )\n",
    "\n",
    "#     captain_rides_df.to_csv(\n",
    "#         rides_file_name,\n",
    "#         index=False\n",
    "#     )\n",
    "#     print(captain_rides_df.head(), '\\n')\n",
    "\n",
    "# for date in daily_list[2:3]:\n",
    "#     temp_login_hrs_df = get_captain_daily_login_hrs(\n",
    "#         date, city, presto_conn)\n",
    "#     captain_login_hrs_df = pd.concat(\n",
    "#         [captain_login_hrs_df, temp_login_hrs_df])\n",
    "#     print('{} Fetched captain login hours for {} and total captains is {}'.format(\n",
    "#         city, date, temp_login_hrs_df.shape[0]))\n",
    "\n",
    "#     print('captain login hours dataframe to be saved as ', login_hrs_file_name)\n",
    "\n",
    "#     captain_login_hrs_df.to_csv(\n",
    "#         login_hrs_file_name,\n",
    "#         index=False\n",
    "#     )\n",
    "#     print(captain_login_hrs_df.head(), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Defined for Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weekly_captain_metrics(rides_df, login_df, incentive_df,\n",
    "                                     rides_rider_field, rides_date_field,\n",
    "                                     login_rider_field, login_date_field,\n",
    "                                     incentive_rider_field, incentive_date_field\n",
    "                                     ):\n",
    "\n",
    "    \"\"\"\n",
    "    :param rides_df: a dataframe for captain daily link completed rides\n",
    "    :param login_df: a dataframe for captain daily login hours on the platform\n",
    "    :param incentive_df: a dataframe capturing daily and weekly incentive at catpain and day level\n",
    "    :param rides_rider_field: captain id field name in rides df\n",
    "    :param rides_date_field: date field name in rides df\n",
    "    :param login_rider_field: captain id field name in login df\n",
    "    :param login_date_field: date field name in login df\n",
    "    :param incentive_rider_field: captain id field name in incentive df\n",
    "    :param incentive_date_field: date field name in incentive df\n",
    "    :param return: aggregated df at captain and week\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    rides_df['date'] = pd.to_datetime(rides_df[rides_date_field])\n",
    "    rides_df['year'] = (rides_df['date'].dt.isocalendar().year)\n",
    "    rides_df['year'] = rides_df['year'].astype('str')\n",
    "    rides_df['week'] = (rides_df['date'].dt.isocalendar().week)\n",
    "    rides_df['week'] = rides_df['week'].map('{:02}'.format)\n",
    "    rides_df['week_num'] = (\n",
    "        rides_df['year'] +\n",
    "        '-' + \n",
    "        rides_df['week'].astype('str') \n",
    "    )\n",
    "\n",
    "    working_days_df = (\n",
    "        rides_df[[rides_rider_field, rides_date_field, 'week_num']]\n",
    "        .groupby([rides_rider_field, 'week_num'])\n",
    "        .agg(\n",
    "            net_active_days=(rides_date_field, 'nunique')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    rides_df = (\n",
    "        rides_df\n",
    "        .groupby([rides_rider_field, 'week_num'])\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    login_df['date'] = pd.to_datetime(login_df[login_date_field])\n",
    "    login_df['year'] = login_df['date'].dt.isocalendar().year\n",
    "    login_df['year'] = login_df['year'].astype('str')\n",
    "    login_df['week'] = (login_df['date'].dt.isocalendar().week)\n",
    "    login_df['week'] = login_df['week'].map('{:02}'.format)\n",
    "    login_df['week_num'] = (\n",
    "        login_df['year'] +\n",
    "        '-' +\n",
    "        login_df['week'].astype('str')\n",
    "    )\n",
    "\n",
    "    login_df = (\n",
    "        login_df\n",
    "        .groupby([login_rider_field, 'week_num'])\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    incentive_df['date'] = pd.to_datetime(incentive_df[incentive_date_field])\n",
    "    incentive_df['year'] = incentive_df['date'].dt.isocalendar().year\n",
    "    incentive_df['year'] = incentive_df['year'].astype('str')\n",
    "    incentive_df['week'] = (incentive_df['date'].dt.isocalendar().week)\n",
    "    incentive_df['week'] = incentive_df['week'].map('{:02}'.format)\n",
    "    incentive_df['week_num'] = (\n",
    "        incentive_df['year'] +\n",
    "        '-' +\n",
    "        incentive_df['week'].astype('str')\n",
    "    )\n",
    "\n",
    "    incentive_df = (\n",
    "        incentive_df\n",
    "        .groupby([incentive_rider_field, 'week_num'])\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    final_df = (\n",
    "        rides_df\n",
    "        .merge(\n",
    "            login_df,\n",
    "            left_on=[rides_rider_field, 'week_num'],\n",
    "            right_on=[login_rider_field, 'week_num'],\n",
    "            how='left',\n",
    "            suffixes=(('', '_right'))\n",
    "        )\n",
    "        .merge(\n",
    "            incentive_df,\n",
    "            left_on=[rides_rider_field, 'week_num'],\n",
    "            right_on=[incentive_rider_field, 'week_num'],\n",
    "            how='left',\n",
    "            suffixes=(('', '_right'))\n",
    "        )\n",
    "        .merge(\n",
    "            working_days_df,\n",
    "            on=[rides_rider_field, 'week_num'],\n",
    "            how='left'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "def get_wow_retention(data, rider_col_name, date_col_name):\n",
    "    \"\"\"\n",
    "    :param data: requires pandas dataframe with rider and ride date as the column\n",
    "    :param return: week on week retention dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    data['year'] = (\n",
    "        pd.to_datetime(data[date_col_name])\n",
    "        .dt.isocalendar().year\n",
    "    )\n",
    "\n",
    "    data['week'] = (\n",
    "        pd.to_datetime(data[date_col_name])\n",
    "        .dt.isocalendar().week\n",
    "    )\n",
    "\n",
    "    data['week'] = data.week.map(\"{:02}\".format)\n",
    "\n",
    "    data['week'] = (\n",
    "        data['year'].astype('str') +\n",
    "        '-' +\n",
    "        data['week'].astype('str')\n",
    "    )\n",
    "\n",
    "    weekly_agg_df = (\n",
    "        data[[rider_col_name, 'week']]\n",
    "        .groupby([rider_col_name, 'week'])\n",
    "        .count()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    week_list = weekly_agg_df['week'].unique()\n",
    "    week_list.sort()\n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    for week_one, week_two in zip(week_list[:-1], week_list[1:]):\n",
    "\n",
    "        week_n1_df = (\n",
    "            weekly_agg_df[\n",
    "                weekly_agg_df['week'] == week_one\n",
    "            ]\n",
    "            .rename(\n",
    "                columns={\n",
    "                    'week': 'week_n1',\n",
    "                    rider_col_name: 'rider_wk_n1'\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "        week_n2_df = (\n",
    "            weekly_agg_df[\n",
    "                weekly_agg_df['week'] == week_two\n",
    "            ]\n",
    "            .rename(\n",
    "                columns={\n",
    "                    'week': 'week_n2',\n",
    "                    rider_col_name: 'rider_wk_n2'\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "        wow_df = (\n",
    "            pd.merge(\n",
    "                left=week_n1_df,\n",
    "                right=week_n2_df,\n",
    "                left_on='rider_wk_n1',\n",
    "                right_on='rider_wk_n2',\n",
    "                how='left'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        temp_df = pd.concat([temp_df, wow_df])\n",
    "\n",
    "    retention_view_df = (\n",
    "        temp_df\n",
    "        .groupby(['week_n1'])\n",
    "        .agg(\n",
    "            week_in=('rider_wk_n1', 'nunique'),\n",
    "            week_next=('rider_wk_n2', 'nunique')\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'week_n1': 'week'})\n",
    "    )\n",
    "\n",
    "    return retention_view_df\n",
    "\n",
    "\n",
    "def get_captain_daily_level_metrics(rides_df, login_df, incentive_df,\n",
    "                                     selectors_df, rides_rider_field, rides_date_field,\n",
    "                                     login_rider_field, login_date_field, incentive_rider_field,\n",
    "                                     incentive_date_field, selector_rider_field\n",
    "                                     ):\n",
    "\n",
    "    \"\"\"\n",
    "    :param rides_df: a dataframe for captain daily link completed rides\n",
    "    :param login_df: a dataframe for captain daily login hours on the platform\n",
    "    :param incentive_df: a dataframe capturing daily and weekly incentive at catpain and day level\n",
    "    :param rides_rider_field: captain id field name in rides df\n",
    "    :param rides_date_field: date field name in rides df\n",
    "    :param login_rider_field: captain id field name in login df\n",
    "    :param login_date_field: date field name in login df\n",
    "    :param incentive_rider_field: captain id field name in incentive df\n",
    "    :param incentive_date_field: date field name in incentive df\n",
    "    :param return: aggregated df at captain and week\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    rides_df['date'] = pd.to_datetime(rides_df[rides_date_field])\n",
    "    login_df['date'] = pd.to_datetime(login_df[login_date_field])\n",
    "    incentive_df['date'] = pd.to_datetime(incentive_df[incentive_date_field])\n",
    "\n",
    "    final_df = (\n",
    "        rides_df\n",
    "        .merge(\n",
    "            login_df,\n",
    "            left_on=[rides_rider_field, 'date'],\n",
    "            right_on=[login_rider_field, 'date'],\n",
    "            how='left',\n",
    "            suffixes=(('', '_right'))\n",
    "        )\n",
    "        .merge(\n",
    "            incentive_df,\n",
    "            left_on=[rides_rider_field, 'date'],\n",
    "            right_on=[incentive_rider_field, 'date'],\n",
    "            how='left',\n",
    "            suffixes=(('', '_right'))\n",
    "        )\n",
    "    )\n",
    "    print(final_df.head())\n",
    "\n",
    "    final_df['year'] = (final_df['date'].dt.isocalendar().year)\n",
    "    final_df['year'] = final_df['year'].astype('str')\n",
    "    final_df['week'] = (final_df['date'].dt.isocalendar().week)\n",
    "    final_df['week'] = final_df['week'].map('{:02}'.format)\n",
    "    final_df['week_num'] = (\n",
    "        final_df['year'] + '-' +\n",
    "        final_df['week'].astype('str')\n",
    "    )\n",
    "    \n",
    "    final_df = (\n",
    "        final_df\n",
    "        .merge(\n",
    "            selectors_df,\n",
    "            left_on=[rides_rider_field],\n",
    "            right_on=[selector_rider_field],\n",
    "            how='left',\n",
    "            suffixes=('', '_right')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def compute_aggregated_metrics(\n",
    "        captain_daily_agg_df, grouping_var,\n",
    "        agg_fields, agg_funcs):\n",
    "\n",
    "    agg_df = (\n",
    "        captain_daily_agg_df\n",
    "        .groupby(grouping_var)\n",
    "        .agg(\n",
    "            dict(zip(agg_fields, agg_funcs))\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return agg_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metric computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mumbai_experiment_selector_wk_23.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read last week\n",
    "experiment_name = 'experiment_selector'\n",
    "perf_wk = '23'\n",
    "experiment_selectors_file = (\n",
    "    '{city}_{experiment_name}_wk_{week_num}.csv'\n",
    "    .format(city=city, experiment_name=experiment_name, week_num=perf_wk)\n",
    ")\n",
    "experiment_selectors_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading last week Mumbai selector ...\n",
      "*************************************************************************** \n",
      " Week 23 selectors view: \n",
      "                       rider   poc_segment  mobilenumber    experiment_group\n",
      "0  62295b72bbd06007fae57e26  UHP_Intra_HO    9930771525  control_ride_group\n",
      "1  61bddec34fc413806e358867  UHP_Intra_HO    7507505554    test_poc_segment\n",
      "2  620629e66e47ef4c20f4589a   MP_Inter_LO    9607238212  control_ride_group\n",
      "3  62380ef5a63f41cf8cd845d8   MP_Inter_LO    7571020664  control_ride_group\n",
      "4  61cc11929ba372650a2db19c   MP_Inter_LO    8082091734  control_ride_group \n",
      "\n"
     ]
    }
   ],
   "source": [
    "old_new_segment_match_df = pd.read_csv('poc_old_new_segment_mapping.csv')\n",
    "segment_col_name = 'poc_segment'\n",
    "old_new_segment_match_df.head()\n",
    "old_new_segment_match_df.rename(\n",
    "    columns={'segment': segment_col_name},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "print(\"reading last week {city} selector ...\".format(city=city))\n",
    "selectors_df = pd.read_csv(experiment_selectors_file)\n",
    "print(\n",
    "    '*' * 75, '\\n',\n",
    "    'Week {} selectors view: \\n'.format(perf_wk),\n",
    "    selectors_df.head(), '\\n'\n",
    ")\n",
    "\n",
    "selectors_df = selectors_df.merge(\n",
    "    old_new_segment_match_df,\n",
    "    on=[segment_col_name],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "selectors_df[segment_col_name] = selectors_df['req_segment']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [weekly aggregated view]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************** \n",
      " Week 23 captain level aggregate metric: \n",
      "                  captain_id week_num  dropped_order  morning_order  \\\n",
      "0  57dc4c0f724beb006ab37b0c  2022-23             13              0   \n",
      "1  582b8985a9924a8572313ad7  2022-23              7              1   \n",
      "2  5858a163417054710ef1e496  2022-23              4              4   \n",
      "3  598cb1d2bf125c4459811cf9  2022-23              3              0   \n",
      "4  59ad5bc75564bc9b1a5f9a0c  2022-23              3              1   \n",
      "\n",
      "   afternoon_order  evening_night_order  mid_night_order  login_hours  \\\n",
      "0                1                   12                0     6.261111   \n",
      "1                0                    4                2    11.585556   \n",
      "2                0                    0                0     2.541667   \n",
      "3                0                    3                0     1.301944   \n",
      "4                0                    2                0     3.441389   \n",
      "\n",
      "   morning_duration  afternoon_duration  evening_duration  \\\n",
      "0          0.000000            1.801944          4.459167   \n",
      "1          0.489167            0.000000          6.480278   \n",
      "2          2.541667            0.000000          0.000000   \n",
      "3          0.000000            0.010278          1.291667   \n",
      "4          0.307500            0.000000          3.125278   \n",
      "\n",
      "                    riderid  daily_incentive_amt  weekly_incentive_amt  \\\n",
      "0  57dc4c0f724beb006ab37b0c                170.0                   0.0   \n",
      "1  582b8985a9924a8572313ad7                 60.0                   0.0   \n",
      "2  5858a163417054710ef1e496                 50.0                   0.0   \n",
      "3  598cb1d2bf125c4459811cf9                 30.0                   0.0   \n",
      "4  59ad5bc75564bc9b1a5f9a0c                 20.0                   0.0   \n",
      "\n",
      "   net_active_days  daily_rpr  \n",
      "0                2        6.5  \n",
      "1                2        3.5  \n",
      "2                1        4.0  \n",
      "3                1        3.0  \n",
      "4                1        3.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# experiment_selectors_file = (\n",
    "#     '{city}_selectors_wk_{week_num}.csv'\n",
    "#     .format(city=city, week_num=perf_wk)\n",
    "# )\n",
    "\n",
    "captain_weekly_agg_df = compute_weekly_captain_metrics(\n",
    "    rides_df=captain_rides_df,\n",
    "    login_df=captain_login_hrs_df,\n",
    "    incentive_df=incentive_amt_df,\n",
    "    rides_rider_field='captain_id',\n",
    "    rides_date_field='order_date',\n",
    "    login_rider_field='captain_id',\n",
    "    login_date_field='logindate',\n",
    "    incentive_rider_field='riderid',\n",
    "    incentive_date_field='yyyymmdd'\n",
    ")\n",
    "\n",
    "captain_weekly_agg_df['daily_rpr'] =(\n",
    "    captain_weekly_agg_df['dropped_order'] /\n",
    "    captain_weekly_agg_df['net_active_days']\n",
    ") \n",
    "\n",
    "print(\n",
    "    '*' * 75, '\\n',\n",
    "    'Week {} captain level aggregate metric: \\n'.format(perf_wk),\n",
    "    captain_weekly_agg_df.head()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # selectors_df.head()\n",
    "# def fetch_rider_info_from_svoc(city, presto_conn_details):\n",
    "#     query = \"\"\"\n",
    "#             select \n",
    "#                 captainid as captain_id,\n",
    "#                 mobilenumber, lastridedate, shift\n",
    "#             from datasets.captain_single_view\n",
    "#             where (lastridecity = '{city}' or registeredcity = lower('{city}'))\n",
    "#         \"\"\".format(city=city)\n",
    "\n",
    "#     svoc_df = pd.read_sql_query(query, presto_conn_details)\n",
    "\n",
    "#     return svoc_df\n",
    "\n",
    "\n",
    "# svoc_file_name = '{city}_svoc_df_wk_{week_num}.csv'.format(\n",
    "#     city=city, week_num=perf_wk)\n",
    "\n",
    "# if not(os.path.exists(svoc_file_name)):\n",
    "#     svoc_df = fetch_rider_info_from_svoc(city, presto_conn)\n",
    "#     svoc_df['mobilenumber'] = svoc_df['mobilenumber'].astype('str')\n",
    "#     svoc_df.to_csv(svoc_file_name, index=False)\n",
    "# else:\n",
    "#     svoc_df = pd.read_csv(svoc_file_name)\n",
    "#     svoc_df['mobilenumber'] = svoc_df['mobilenumber'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_experiment_performance(weekly_agg_df, weekly_agg_rider_field, selector_df,\n",
    " selector_rider_field, experiment_group_name, segment_col_name):\n",
    "    \"\"\"\n",
    "    :param weekly_agg_df: captain level weekly aggregated dataframe\n",
    "    :param selector_df: a df having captain id with their cohort and segment\n",
    "    \"\"\"\n",
    "\n",
    "    req_fields = [\n",
    "        'rider', 'week_num', 'dropped_order', 'login_hours',\n",
    "        'morning_duration', 'afternoon_duration', 'evening_duration',\n",
    "        'daily_incentive_amt', 'weekly_incentive_amt', 'daily_rpr'\n",
    "        # 'simplified_segment', 'cohort',\n",
    "    ]\n",
    "\n",
    "    experiment_analysis_df = (\n",
    "        weekly_agg_df\n",
    "        .merge(\n",
    "            selector_df,\n",
    "            left_on=[weekly_agg_rider_field],\n",
    "            right_on=[selector_rider_field],\n",
    "            how='inner'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # calculate the agg view at experiment group and segment group\n",
    "    level_1_grouping_vars = ['week_num', experiment_group_name]\n",
    "    level_1_agg_df = experiment_analysis_df.groupby(level_1_grouping_vars)\n",
    "    level_1_selectors_size_df = (\n",
    "        selector_df[level_1_grouping_vars[1:] + [selector_rider_field]]\n",
    "        .groupby(level_1_grouping_vars[1:])\n",
    "        .agg(\n",
    "            {\n",
    "                selector_rider_field: 'nunique',\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    level_1_analysis_agg_df = (\n",
    "        level_1_agg_df[req_fields[:-1]].sum().reset_index()\n",
    "        .merge(\n",
    "            level_1_agg_df\n",
    "            .agg(\n",
    "                net_riders=(weekly_agg_rider_field, 'nunique'),\n",
    "                median_active_days=('net_active_days', 'median'),\n",
    "                daily_rpr=('daily_rpr', 'mean')\n",
    "            )\n",
    "            .reset_index(),\n",
    "            on=level_1_grouping_vars,\n",
    "            how='left'\n",
    "        )\n",
    "        .merge(\n",
    "            level_1_selectors_size_df,\n",
    "            on=level_1_grouping_vars[1:],\n",
    "            how='left'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # calculate the agg view at experiment group and segment group\n",
    "    level_2_grouping_vars = [\n",
    "        'week_num',experiment_group_name, segment_col_name\n",
    "    ]\n",
    "    level_2_agg_df = experiment_analysis_df.groupby(level_2_grouping_vars)\n",
    "    level_2_selectors_size_df = (\n",
    "        selector_df[level_2_grouping_vars[1:] + [selector_rider_field]]\n",
    "        .groupby(level_2_grouping_vars[1:])\n",
    "        .agg({selector_rider_field: 'nunique'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    level_2_analysis_agg_df = (\n",
    "        level_2_agg_df[req_fields[:-1]].sum().reset_index()\n",
    "        .merge(\n",
    "            level_2_agg_df\n",
    "            .agg(\n",
    "                net_riders=('captain_id', 'nunique'),\n",
    "                median_active_days=('net_active_days', 'median'),\n",
    "                daily_rpr=('daily_rpr', 'mean')\n",
    "            )\n",
    "            .reset_index(),\n",
    "            on=level_2_grouping_vars,\n",
    "            how='left'\n",
    "        )\n",
    "        .merge(\n",
    "            level_2_selectors_size_df,\n",
    "            on=level_2_grouping_vars[1:],\n",
    "            how='left'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(level_2_analysis_agg_df.head())\n",
    "\n",
    "    analysis_agg_df = pd.concat(\n",
    "        [\n",
    "            level_2_analysis_agg_df,\n",
    "            level_1_analysis_agg_df,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    analysis_agg_df['total_incentive']=(\n",
    "        analysis_agg_df['daily_incentive_amt'] + \n",
    "        analysis_agg_df['weekly_incentive_amt']\n",
    "    )\n",
    "\n",
    "    analysis_agg_df['rpr'] = (\n",
    "        analysis_agg_df['dropped_order'] /\n",
    "        analysis_agg_df['net_riders']\n",
    "    )\n",
    "\n",
    "    analysis_agg_df['burn_per_rider'] = (\n",
    "        analysis_agg_df['total_incentive'] /\n",
    "        analysis_agg_df['net_riders']\n",
    "    )\n",
    "\n",
    "    analysis_agg_df['weekly_burn_per_rider'] = (\n",
    "        analysis_agg_df['weekly_incentive_amt'] /\n",
    "        analysis_agg_df['net_riders']\n",
    "    )\n",
    "\n",
    "    analysis_agg_df['weekly_burn_per_rider'] = (\n",
    "        analysis_agg_df['weekly_incentive_amt'] /\n",
    "        analysis_agg_df['net_riders']\n",
    "    )\n",
    "\n",
    "    analysis_agg_df['daily_burn_per_rider'] = (\n",
    "        analysis_agg_df['daily_incentive_amt'] /\n",
    "        analysis_agg_df['net_riders']\n",
    "    )\n",
    "\n",
    "    analysis_agg_df['rph'] = (\n",
    "        analysis_agg_df['dropped_order'] /\n",
    "        analysis_agg_df['login_hours']\n",
    "    )\n",
    "\n",
    "    analysis_agg_df['daily_burn_per_ride'] = (\n",
    "        analysis_agg_df['daily_incentive_amt'] /\n",
    "        analysis_agg_df['dropped_order']\n",
    "    )\n",
    "\n",
    "    analysis_agg_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    rearrange_cols = [\n",
    "        'week_num', segment_col_name, experiment_group_name,\n",
    "         selector_rider_field, 'net_riders', 'dropped_order',  'rpr',\n",
    "        'burn_per_rider', 'weekly_burn_per_rider',\n",
    "        'daily_burn_per_rider', 'median_active_days', 'rph',\n",
    "        'daily_rpr', 'daily_burn_per_ride', 'daily_incentive_amt',\n",
    "        'weekly_incentive_amt'\n",
    "    ]\n",
    "\n",
    "\n",
    "    return analysis_agg_df[rearrange_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  week_num    experiment_group poc_segment  dropped_order  login_hours  \\\n",
      "0  2022-23  control_ride_group     HP_D_HO           2403  1796.699444   \n",
      "1  2022-23  control_ride_group     HP_D_MO            205   131.834722   \n",
      "2  2022-23  control_ride_group    HP_D_UHO           3387  2368.337222   \n",
      "3  2022-23  control_ride_group     LP_D_HO            268   406.279444   \n",
      "4  2022-23  control_ride_group     LP_D_LO            621   580.175833   \n",
      "\n",
      "   morning_duration  afternoon_duration  evening_duration  \\\n",
      "0        363.510000          536.212778        777.637222   \n",
      "1         50.460556           27.515278         50.948611   \n",
      "2        430.431944          776.839167       1036.639722   \n",
      "3         58.692778          138.060278        180.062222   \n",
      "4        106.203611          143.544444        277.998056   \n",
      "\n",
      "   daily_incentive_amt  weekly_incentive_amt  net_riders  median_active_days  \\\n",
      "0              19920.0                1130.0         190                 2.0   \n",
      "1               2040.0                 440.0          15                 2.0   \n",
      "2              30275.0                2910.0         223                 2.0   \n",
      "3               1965.0                   0.0          54                 2.0   \n",
      "4               5490.0                1280.0         104                 1.5   \n",
      "\n",
      "   daily_rpr  rider  \n",
      "0   5.937719    304  \n",
      "1   6.488889     23  \n",
      "2   6.801943    392  \n",
      "3   2.783951    126  \n",
      "4   3.157051    273  \n",
      "   week_num poc_segment    experiment_group  rider  net_riders  dropped_order  \\\n",
      "0   2022-23     HP_D_HO  control_ride_group    304         190           2403   \n",
      "1   2022-23     HP_D_MO  control_ride_group     23          15            205   \n",
      "2   2022-23    HP_D_UHO  control_ride_group    392         223           3387   \n",
      "3   2022-23     LP_D_HO  control_ride_group    126          54            268   \n",
      "4   2022-23     LP_D_LO  control_ride_group    273         104            621   \n",
      "5   2022-23     LP_D_MO  control_ride_group    206          93            478   \n",
      "6   2022-23    LP_D_UHO  control_ride_group    121          57            294   \n",
      "7   2022-23     MP_D_HO  control_ride_group    270         145           1382   \n",
      "8   2022-23     MP_D_LO  control_ride_group     41          21            130   \n",
      "9   2022-23     MP_D_MO  control_ride_group    379         173           1478   \n",
      "10  2022-23    MP_D_UHO  control_ride_group    243         131           1253   \n",
      "11  2022-23   UHP_D_UHO  control_ride_group    576         387          10078   \n",
      "12  2022-23     HP_D_HO    test_poc_segment    306         174           2351   \n",
      "13  2022-23     HP_D_MO    test_poc_segment     23          13            150   \n",
      "14  2022-23    HP_D_UHO    test_poc_segment    393         224           3415   \n",
      "15  2022-23     LP_D_HO    test_poc_segment    128          55            315   \n",
      "16  2022-23     LP_D_LO    test_poc_segment    274          97            453   \n",
      "17  2022-23     LP_D_MO    test_poc_segment    208          80            385   \n",
      "18  2022-23    LP_D_UHO    test_poc_segment    122          40            249   \n",
      "19  2022-23     MP_D_HO    test_poc_segment    272         147           1333   \n",
      "20  2022-23     MP_D_LO    test_poc_segment     43          21             77   \n",
      "21  2022-23     MP_D_MO    test_poc_segment    382         192           1479   \n",
      "22  2022-23    MP_D_UHO    test_poc_segment    245         140           1339   \n",
      "23  2022-23   UHP_D_UHO    test_poc_segment    578         381           9510   \n",
      "24  2022-23         NaN  control_ride_group   2971        1603          22095   \n",
      "25  2022-23         NaN    test_poc_segment   2993        1572          21175   \n",
      "\n",
      "          rpr  burn_per_rider  weekly_burn_per_rider  daily_burn_per_rider  \\\n",
      "0   12.647368      110.789474               5.947368            104.842105   \n",
      "1   13.666667      165.333333              29.333333            136.000000   \n",
      "2   15.188341      148.811659              13.049327            135.762332   \n",
      "3    4.962963       36.388889               0.000000             36.388889   \n",
      "4    5.971154       65.096154              12.307692             52.788462   \n",
      "5    5.139785       49.838710               7.849462             41.989247   \n",
      "6    5.157895       40.000000               0.000000             40.000000   \n",
      "7    9.531034       99.931034              14.827586             85.103448   \n",
      "8    6.190476       47.142857               0.000000             47.142857   \n",
      "9    8.543353       87.109827               7.803468             79.306358   \n",
      "10   9.564885       89.694656               9.389313             80.305344   \n",
      "11  26.041344      264.857881              11.782946            253.074935   \n",
      "12  13.511494       79.310345              12.528736             66.781609   \n",
      "13  11.538462       82.307692               0.000000             82.307692   \n",
      "14  15.245536      110.580357              17.008929             93.571429   \n",
      "15   5.727273       52.363636               6.000000             46.363636   \n",
      "16   4.670103       39.381443               5.463918             33.917526   \n",
      "17   4.812500       32.250000               0.000000             32.250000   \n",
      "18   6.225000       70.000000              14.500000             55.500000   \n",
      "19   9.068027       62.312925               8.775510             53.537415   \n",
      "20   3.666667       11.428571               0.000000             11.428571   \n",
      "21   7.703125       51.093750               7.812500             43.281250   \n",
      "22   9.564286       77.714286              14.000000             63.714286   \n",
      "23  24.960630      221.207349              17.427822            203.779528   \n",
      "24  13.783531      136.690580              10.205864            126.484716   \n",
      "25  13.470102      106.113232              11.972010             94.141221   \n",
      "\n",
      "    median_active_days       rph  daily_rpr  daily_burn_per_ride  \\\n",
      "0                  2.0  1.337452   5.937719             8.289638   \n",
      "1                  2.0  1.554977   6.488889             9.951220   \n",
      "2                  2.0  1.430117   6.801943             8.938589   \n",
      "3                  2.0  0.659644   2.783951             7.332090   \n",
      "4                  1.5  1.070365   3.157051             8.840580   \n",
      "5                  2.0  0.777666   2.634409             8.169456   \n",
      "6                  2.0  0.540856   2.710526             7.755102   \n",
      "7                  2.0  1.150405   4.364368             8.929088   \n",
      "8                  2.0  1.196417   3.182540             7.615385   \n",
      "9                  2.0  1.218485   4.531792             9.282815   \n",
      "10                 2.0  1.029141   4.400763             8.395850   \n",
      "11                 3.0  1.724552  10.566322             9.718198   \n",
      "12                 2.0  1.366967   6.105364             4.942578   \n",
      "13                 2.0  1.448867   5.051282             7.133333   \n",
      "14                 2.0  1.386928   6.696429             6.137628   \n",
      "15                 2.0  0.743879   3.060606             8.095238   \n",
      "16                 1.0  0.979982   2.548110             7.262693   \n",
      "17                 2.0  0.848298   2.593750             6.701299   \n",
      "18                 2.0  0.717533   3.333333             8.915663   \n",
      "19                 2.0  1.102176   4.209751             5.903976   \n",
      "20                 1.0  0.990000   2.293651             3.116883   \n",
      "21                 2.0  1.231046   3.923611             5.618661   \n",
      "22                 2.0  0.944183   4.461905             6.661688   \n",
      "23                 2.0  1.663240  10.479440             8.164038   \n",
      "24                 2.0  1.372155   6.130796             9.176511   \n",
      "25                 2.0  1.350072   6.027990             6.988902   \n",
      "\n",
      "    daily_incentive_amt  weekly_incentive_amt  \n",
      "0               19920.0                1130.0  \n",
      "1                2040.0                 440.0  \n",
      "2               30275.0                2910.0  \n",
      "3                1965.0                   0.0  \n",
      "4                5490.0                1280.0  \n",
      "5                3905.0                 730.0  \n",
      "6                2280.0                   0.0  \n",
      "7               12340.0                2150.0  \n",
      "8                 990.0                   0.0  \n",
      "9               13720.0                1350.0  \n",
      "10              10520.0                1230.0  \n",
      "11              97940.0                4560.0  \n",
      "12              11620.0                2180.0  \n",
      "13               1070.0                   0.0  \n",
      "14              20960.0                3810.0  \n",
      "15               2550.0                 330.0  \n",
      "16               3290.0                 530.0  \n",
      "17               2580.0                   0.0  \n",
      "18               2220.0                 580.0  \n",
      "19               7870.0                1290.0  \n",
      "20                240.0                   0.0  \n",
      "21               8310.0                1500.0  \n",
      "22               8920.0                1960.0  \n",
      "23              77640.0                6640.0  \n",
      "24             202755.0               16360.0  \n",
      "25             147990.0               18820.0  \n"
     ]
    }
   ],
   "source": [
    "analysis_agg_df = get_experiment_performance(\n",
    "    weekly_agg_df=captain_weekly_agg_df,\n",
    "    selector_df=selectors_df,\n",
    "    weekly_agg_rider_field='captain_id',\n",
    "    selector_rider_field='rider',\n",
    "    experiment_group_name='experiment_group',\n",
    "    segment_col_name=segment_col_name\n",
    ")\n",
    "\n",
    "analysis_agg_df.to_clipboard()\n",
    "print(analysis_agg_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Aggregated View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  city_name  order_date                captain_id  dropped_order  \\\n",
      "0    Mumbai  2022-06-06  612c7eb334b93de406358227              2   \n",
      "1    Mumbai  2022-06-06  610a46c780f61d07762cc5d4             20   \n",
      "2    Mumbai  2022-06-06  62971adfa81bc548e659e1f4             11   \n",
      "3    Mumbai  2022-06-06  5e728b45f49633436e2fa906              6   \n",
      "4    Mumbai  2022-06-06  6234b3da6b6b643417706f1b             10   \n",
      "\n",
      "   morning_order  afternoon_order  evening_night_order  mid_night_order  \\\n",
      "0              0                0                    0                2   \n",
      "1              0                7                    8                5   \n",
      "2              2                3                    3                3   \n",
      "3              0                4                    2                0   \n",
      "4              0                4                    5                1   \n",
      "\n",
      "        date   logindate  login_hours  morning_duration  afternoon_duration  \\\n",
      "0 2022-06-06  2022-06-06     1.244167          0.000000            0.000000   \n",
      "1 2022-06-06  2022-06-06     9.492500          0.000000            4.380833   \n",
      "2 2022-06-06  2022-06-06     9.240833          0.731667            2.393889   \n",
      "3 2022-06-06  2022-06-06     5.020278          0.000000            3.782500   \n",
      "4 2022-06-06  2022-06-06     5.378889          0.000000            2.855000   \n",
      "\n",
      "   evening_duration   yyyymmdd   startdate                   riderid  \\\n",
      "0          0.000000        NaT         NaN                       NaN   \n",
      "1          2.793889 2022-06-06  2022-06-06  610a46c780f61d07762cc5d4   \n",
      "2          2.766944 2022-06-06  2022-06-06  62971adfa81bc548e659e1f4   \n",
      "3          1.237778 2022-06-06  2022-06-06  5e728b45f49633436e2fa906   \n",
      "4          2.076389 2022-06-06  2022-06-06  6234b3da6b6b643417706f1b   \n",
      "\n",
      "   daily_incentive_amt  weekly_incentive_amt  \n",
      "0                  NaN                   NaN  \n",
      "1                170.0                   NaN  \n",
      "2                140.0                   NaN  \n",
      "3                 20.0                   NaN  \n",
      "4                140.0                   NaN  \n",
      "*************************************************************************** \n",
      " Week 23 captain level aggregate metric: \n",
      "   city_name  order_date                captain_id  dropped_order  \\\n",
      "0    Mumbai  2022-06-06  612c7eb334b93de406358227              2   \n",
      "1    Mumbai  2022-06-06  610a46c780f61d07762cc5d4             20   \n",
      "2    Mumbai  2022-06-06  62971adfa81bc548e659e1f4             11   \n",
      "3    Mumbai  2022-06-06  5e728b45f49633436e2fa906              6   \n",
      "4    Mumbai  2022-06-06  6234b3da6b6b643417706f1b             10   \n",
      "\n",
      "   morning_order  afternoon_order  evening_night_order  mid_night_order  \\\n",
      "0              0                0                    0                2   \n",
      "1              0                7                    8                5   \n",
      "2              2                3                    3                3   \n",
      "3              0                4                    2                0   \n",
      "4              0                4                    5                1   \n",
      "\n",
      "        date   logindate  ...  daily_incentive_amt  weekly_incentive_amt  \\\n",
      "0 2022-06-06  2022-06-06  ...                  NaN                   NaN   \n",
      "1 2022-06-06  2022-06-06  ...                170.0                   NaN   \n",
      "2 2022-06-06  2022-06-06  ...                140.0                   NaN   \n",
      "3 2022-06-06  2022-06-06  ...                 20.0                   NaN   \n",
      "4 2022-06-06  2022-06-06  ...                140.0                   NaN   \n",
      "\n",
      "   year  week week_num                     rider poc_segment  mobilenumber  \\\n",
      "0  2022    23  2022-23  612c7eb334b93de406358227     MP_D_MO  8.850207e+09   \n",
      "1  2022    23  2022-23  610a46c780f61d07762cc5d4   UHP_D_UHO  9.821748e+09   \n",
      "2  2022    23  2022-23                       NaN         NaN           NaN   \n",
      "3  2022    23  2022-23                       NaN         NaN           NaN   \n",
      "4  2022    23  2022-23                       NaN         NaN           NaN   \n",
      "\n",
      "     experiment_group req_segment  \n",
      "0  control_ride_group     MP_D_MO  \n",
      "1    test_poc_segment   UHP_D_UHO  \n",
      "2                 NaN         NaN  \n",
      "3                 NaN         NaN  \n",
      "4                 NaN         NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>week_num</th>\n",
       "      <th>poc_segment</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>captain_id</th>\n",
       "      <th>selector_size</th>\n",
       "      <th>dropped_order</th>\n",
       "      <th>morning_order</th>\n",
       "      <th>afternoon_order</th>\n",
       "      <th>evening_night_order</th>\n",
       "      <th>mid_night_order</th>\n",
       "      <th>morning_duration</th>\n",
       "      <th>afternoon_duration</th>\n",
       "      <th>evening_duration</th>\n",
       "      <th>daily_incentive_amt</th>\n",
       "      <th>weekly_incentive_amt</th>\n",
       "      <th>daily_burn_per_rider</th>\n",
       "      <th>daily_burn_per_ride</th>\n",
       "      <th>daily_avg_rpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>HP_D_HO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>190</td>\n",
       "      <td>304</td>\n",
       "      <td>2403</td>\n",
       "      <td>538</td>\n",
       "      <td>572</td>\n",
       "      <td>1136</td>\n",
       "      <td>157</td>\n",
       "      <td>359.228056</td>\n",
       "      <td>522.410833</td>\n",
       "      <td>766.145556</td>\n",
       "      <td>19810.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>50.714440</td>\n",
       "      <td>8.237227</td>\n",
       "      <td>6.145780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>HP_D_HO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>174</td>\n",
       "      <td>306</td>\n",
       "      <td>2351</td>\n",
       "      <td>573</td>\n",
       "      <td>466</td>\n",
       "      <td>1239</td>\n",
       "      <td>73</td>\n",
       "      <td>358.323611</td>\n",
       "      <td>464.874167</td>\n",
       "      <td>791.358889</td>\n",
       "      <td>11520.0</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>31.846840</td>\n",
       "      <td>4.893603</td>\n",
       "      <td>6.494475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>HP_D_MO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>205</td>\n",
       "      <td>96</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>49.967222</td>\n",
       "      <td>26.953333</td>\n",
       "      <td>49.839444</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>69.519481</td>\n",
       "      <td>9.568013</td>\n",
       "      <td>7.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>HP_D_MO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>150</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>71</td>\n",
       "      <td>12</td>\n",
       "      <td>32.296667</td>\n",
       "      <td>18.943333</td>\n",
       "      <td>42.395833</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.888889</td>\n",
       "      <td>6.905310</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>HP_D_UHO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>223</td>\n",
       "      <td>392</td>\n",
       "      <td>3387</td>\n",
       "      <td>755</td>\n",
       "      <td>899</td>\n",
       "      <td>1601</td>\n",
       "      <td>132</td>\n",
       "      <td>423.277222</td>\n",
       "      <td>752.500833</td>\n",
       "      <td>988.822222</td>\n",
       "      <td>30025.0</td>\n",
       "      <td>2910.0</td>\n",
       "      <td>63.442581</td>\n",
       "      <td>8.847660</td>\n",
       "      <td>7.160677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>HP_D_UHO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>224</td>\n",
       "      <td>393</td>\n",
       "      <td>3415</td>\n",
       "      <td>818</td>\n",
       "      <td>929</td>\n",
       "      <td>1514</td>\n",
       "      <td>154</td>\n",
       "      <td>488.476111</td>\n",
       "      <td>787.748056</td>\n",
       "      <td>953.593889</td>\n",
       "      <td>20660.0</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>43.444878</td>\n",
       "      <td>6.031799</td>\n",
       "      <td>7.174370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>LP_D_HO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>54</td>\n",
       "      <td>126</td>\n",
       "      <td>268</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>130</td>\n",
       "      <td>12</td>\n",
       "      <td>50.225278</td>\n",
       "      <td>111.675278</td>\n",
       "      <td>155.657500</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.633180</td>\n",
       "      <td>7.010909</td>\n",
       "      <td>2.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>LP_D_HO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>55</td>\n",
       "      <td>128</td>\n",
       "      <td>315</td>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>15</td>\n",
       "      <td>42.102500</td>\n",
       "      <td>108.495000</td>\n",
       "      <td>152.604167</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>27.483245</td>\n",
       "      <td>8.129064</td>\n",
       "      <td>3.351064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>LP_D_LO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>104</td>\n",
       "      <td>273</td>\n",
       "      <td>621</td>\n",
       "      <td>130</td>\n",
       "      <td>138</td>\n",
       "      <td>305</td>\n",
       "      <td>48</td>\n",
       "      <td>96.843333</td>\n",
       "      <td>127.978333</td>\n",
       "      <td>254.166389</td>\n",
       "      <td>5420.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>31.688596</td>\n",
       "      <td>8.702160</td>\n",
       "      <td>3.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>LP_D_LO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>97</td>\n",
       "      <td>274</td>\n",
       "      <td>453</td>\n",
       "      <td>88</td>\n",
       "      <td>74</td>\n",
       "      <td>252</td>\n",
       "      <td>39</td>\n",
       "      <td>55.530556</td>\n",
       "      <td>99.444722</td>\n",
       "      <td>220.583056</td>\n",
       "      <td>3230.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>21.126543</td>\n",
       "      <td>7.102999</td>\n",
       "      <td>2.980263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>LP_D_MO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>93</td>\n",
       "      <td>206</td>\n",
       "      <td>478</td>\n",
       "      <td>120</td>\n",
       "      <td>83</td>\n",
       "      <td>257</td>\n",
       "      <td>18</td>\n",
       "      <td>97.414167</td>\n",
       "      <td>150.409722</td>\n",
       "      <td>247.435556</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>24.502821</td>\n",
       "      <td>8.033088</td>\n",
       "      <td>3.044586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>LP_D_MO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>80</td>\n",
       "      <td>208</td>\n",
       "      <td>385</td>\n",
       "      <td>57</td>\n",
       "      <td>82</td>\n",
       "      <td>209</td>\n",
       "      <td>37</td>\n",
       "      <td>46.385556</td>\n",
       "      <td>108.477222</td>\n",
       "      <td>197.563889</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.322375</td>\n",
       "      <td>6.519501</td>\n",
       "      <td>2.810219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>LP_D_UHO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>57</td>\n",
       "      <td>121</td>\n",
       "      <td>294</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>152</td>\n",
       "      <td>19</td>\n",
       "      <td>55.495833</td>\n",
       "      <td>138.314444</td>\n",
       "      <td>195.057222</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.642143</td>\n",
       "      <td>7.554091</td>\n",
       "      <td>2.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>LP_D_UHO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>40</td>\n",
       "      <td>122</td>\n",
       "      <td>249</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>137</td>\n",
       "      <td>13</td>\n",
       "      <td>49.356944</td>\n",
       "      <td>74.480833</td>\n",
       "      <td>144.350833</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>31.037851</td>\n",
       "      <td>8.808944</td>\n",
       "      <td>3.507042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>MP_D_HO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>145</td>\n",
       "      <td>270</td>\n",
       "      <td>1382</td>\n",
       "      <td>323</td>\n",
       "      <td>365</td>\n",
       "      <td>636</td>\n",
       "      <td>58</td>\n",
       "      <td>229.441389</td>\n",
       "      <td>381.813889</td>\n",
       "      <td>465.253056</td>\n",
       "      <td>12140.0</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>42.572487</td>\n",
       "      <td>8.787810</td>\n",
       "      <td>4.815331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>MP_D_HO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>147</td>\n",
       "      <td>272</td>\n",
       "      <td>1333</td>\n",
       "      <td>351</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>42</td>\n",
       "      <td>247.346111</td>\n",
       "      <td>355.138889</td>\n",
       "      <td>511.566111</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>26.275261</td>\n",
       "      <td>5.808347</td>\n",
       "      <td>4.503378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>MP_D_LO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>130</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>17.186944</td>\n",
       "      <td>22.276944</td>\n",
       "      <td>61.161667</td>\n",
       "      <td>990.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.894231</td>\n",
       "      <td>7.619652</td>\n",
       "      <td>3.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>MP_D_LO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>77</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>7.513056</td>\n",
       "      <td>17.512778</td>\n",
       "      <td>42.968889</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.263403</td>\n",
       "      <td>3.064062</td>\n",
       "      <td>2.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>MP_D_MO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>173</td>\n",
       "      <td>379</td>\n",
       "      <td>1478</td>\n",
       "      <td>357</td>\n",
       "      <td>308</td>\n",
       "      <td>723</td>\n",
       "      <td>90</td>\n",
       "      <td>235.088333</td>\n",
       "      <td>318.469722</td>\n",
       "      <td>541.060833</td>\n",
       "      <td>13580.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>43.453835</td>\n",
       "      <td>9.115020</td>\n",
       "      <td>4.752412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>MP_D_MO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>192</td>\n",
       "      <td>382</td>\n",
       "      <td>1479</td>\n",
       "      <td>312</td>\n",
       "      <td>355</td>\n",
       "      <td>725</td>\n",
       "      <td>87</td>\n",
       "      <td>189.358889</td>\n",
       "      <td>306.833889</td>\n",
       "      <td>547.674722</td>\n",
       "      <td>8310.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>23.563456</td>\n",
       "      <td>5.618727</td>\n",
       "      <td>4.189802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>MP_D_UHO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>131</td>\n",
       "      <td>243</td>\n",
       "      <td>1253</td>\n",
       "      <td>249</td>\n",
       "      <td>267</td>\n",
       "      <td>650</td>\n",
       "      <td>87</td>\n",
       "      <td>186.835000</td>\n",
       "      <td>320.336667</td>\n",
       "      <td>543.446944</td>\n",
       "      <td>10460.0</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>38.829685</td>\n",
       "      <td>8.300338</td>\n",
       "      <td>4.640741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>MP_D_UHO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>140</td>\n",
       "      <td>245</td>\n",
       "      <td>1339</td>\n",
       "      <td>334</td>\n",
       "      <td>328</td>\n",
       "      <td>644</td>\n",
       "      <td>33</td>\n",
       "      <td>237.434444</td>\n",
       "      <td>439.130000</td>\n",
       "      <td>554.032778</td>\n",
       "      <td>8920.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>32.047132</td>\n",
       "      <td>6.599250</td>\n",
       "      <td>4.748227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>UHP_D_UHO</td>\n",
       "      <td>control_ride_group</td>\n",
       "      <td>387</td>\n",
       "      <td>576</td>\n",
       "      <td>10078</td>\n",
       "      <td>2673</td>\n",
       "      <td>3039</td>\n",
       "      <td>4105</td>\n",
       "      <td>261</td>\n",
       "      <td>1369.057500</td>\n",
       "      <td>2176.538611</td>\n",
       "      <td>2076.700278</td>\n",
       "      <td>97510.0</td>\n",
       "      <td>4560.0</td>\n",
       "      <td>109.178942</td>\n",
       "      <td>9.675930</td>\n",
       "      <td>11.272931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>UHP_D_UHO</td>\n",
       "      <td>test_poc_segment</td>\n",
       "      <td>381</td>\n",
       "      <td>578</td>\n",
       "      <td>9510</td>\n",
       "      <td>2501</td>\n",
       "      <td>3061</td>\n",
       "      <td>3706</td>\n",
       "      <td>242</td>\n",
       "      <td>1347.988333</td>\n",
       "      <td>2157.780278</td>\n",
       "      <td>1980.803056</td>\n",
       "      <td>77390.0</td>\n",
       "      <td>6640.0</td>\n",
       "      <td>89.895603</td>\n",
       "      <td>8.138015</td>\n",
       "      <td>11.045296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_name week_num poc_segment    experiment_group  captain_id  \\\n",
       "0     Mumbai  2022-23     HP_D_HO  control_ride_group         190   \n",
       "1     Mumbai  2022-23     HP_D_HO    test_poc_segment         174   \n",
       "2     Mumbai  2022-23     HP_D_MO  control_ride_group          15   \n",
       "3     Mumbai  2022-23     HP_D_MO    test_poc_segment          13   \n",
       "4     Mumbai  2022-23    HP_D_UHO  control_ride_group         223   \n",
       "5     Mumbai  2022-23    HP_D_UHO    test_poc_segment         224   \n",
       "6     Mumbai  2022-23     LP_D_HO  control_ride_group          54   \n",
       "7     Mumbai  2022-23     LP_D_HO    test_poc_segment          55   \n",
       "8     Mumbai  2022-23     LP_D_LO  control_ride_group         104   \n",
       "9     Mumbai  2022-23     LP_D_LO    test_poc_segment          97   \n",
       "10    Mumbai  2022-23     LP_D_MO  control_ride_group          93   \n",
       "11    Mumbai  2022-23     LP_D_MO    test_poc_segment          80   \n",
       "12    Mumbai  2022-23    LP_D_UHO  control_ride_group          57   \n",
       "13    Mumbai  2022-23    LP_D_UHO    test_poc_segment          40   \n",
       "14    Mumbai  2022-23     MP_D_HO  control_ride_group         145   \n",
       "15    Mumbai  2022-23     MP_D_HO    test_poc_segment         147   \n",
       "16    Mumbai  2022-23     MP_D_LO  control_ride_group          21   \n",
       "17    Mumbai  2022-23     MP_D_LO    test_poc_segment          21   \n",
       "18    Mumbai  2022-23     MP_D_MO  control_ride_group         173   \n",
       "19    Mumbai  2022-23     MP_D_MO    test_poc_segment         192   \n",
       "20    Mumbai  2022-23    MP_D_UHO  control_ride_group         131   \n",
       "21    Mumbai  2022-23    MP_D_UHO    test_poc_segment         140   \n",
       "22    Mumbai  2022-23   UHP_D_UHO  control_ride_group         387   \n",
       "23    Mumbai  2022-23   UHP_D_UHO    test_poc_segment         381   \n",
       "\n",
       "    selector_size  dropped_order  morning_order  afternoon_order  \\\n",
       "0             304           2403            538              572   \n",
       "1             306           2351            573              466   \n",
       "2              23            205             96               39   \n",
       "3              23            150             48               19   \n",
       "4             392           3387            755              899   \n",
       "5             393           3415            818              929   \n",
       "6             126            268             56               70   \n",
       "7             128            315             61               77   \n",
       "8             273            621            130              138   \n",
       "9             274            453             88               74   \n",
       "10            206            478            120               83   \n",
       "11            208            385             57               82   \n",
       "12            121            294             56               67   \n",
       "13            122            249             47               52   \n",
       "14            270           1382            323              365   \n",
       "15            272           1333            351              310   \n",
       "16             41            130             30               25   \n",
       "17             43             77             13               14   \n",
       "18            379           1478            357              308   \n",
       "19            382           1479            312              355   \n",
       "20            243           1253            249              267   \n",
       "21            245           1339            334              328   \n",
       "22            576          10078           2673             3039   \n",
       "23            578           9510           2501             3061   \n",
       "\n",
       "    evening_night_order  mid_night_order  morning_duration  \\\n",
       "0                  1136              157        359.228056   \n",
       "1                  1239               73        358.323611   \n",
       "2                    65                5         49.967222   \n",
       "3                    71               12         32.296667   \n",
       "4                  1601              132        423.277222   \n",
       "5                  1514              154        488.476111   \n",
       "6                   130               12         50.225278   \n",
       "7                   162               15         42.102500   \n",
       "8                   305               48         96.843333   \n",
       "9                   252               39         55.530556   \n",
       "10                  257               18         97.414167   \n",
       "11                  209               37         46.385556   \n",
       "12                  152               19         55.495833   \n",
       "13                  137               13         49.356944   \n",
       "14                  636               58        229.441389   \n",
       "15                  630               42        247.346111   \n",
       "16                   68                7         17.186944   \n",
       "17                   50                0          7.513056   \n",
       "18                  723               90        235.088333   \n",
       "19                  725               87        189.358889   \n",
       "20                  650               87        186.835000   \n",
       "21                  644               33        237.434444   \n",
       "22                 4105              261       1369.057500   \n",
       "23                 3706              242       1347.988333   \n",
       "\n",
       "    afternoon_duration  evening_duration  daily_incentive_amt  \\\n",
       "0           522.410833        766.145556              19810.0   \n",
       "1           464.874167        791.358889              11520.0   \n",
       "2            26.953333         49.839444               2010.0   \n",
       "3            18.943333         42.395833               1070.0   \n",
       "4           752.500833        988.822222              30025.0   \n",
       "5           787.748056        953.593889              20660.0   \n",
       "6           111.675278        155.657500               1925.0   \n",
       "7           108.495000        152.604167               2550.0   \n",
       "8           127.978333        254.166389               5420.0   \n",
       "9            99.444722        220.583056               3230.0   \n",
       "10          150.409722        247.435556               3845.0   \n",
       "11          108.477222        197.563889               2520.0   \n",
       "12          138.314444        195.057222               2280.0   \n",
       "13           74.480833        144.350833               2190.0   \n",
       "14          381.813889        465.253056              12140.0   \n",
       "15          355.138889        511.566111               7810.0   \n",
       "16           22.276944         61.161667                990.0   \n",
       "17           17.512778         42.968889                240.0   \n",
       "18          318.469722        541.060833              13580.0   \n",
       "19          306.833889        547.674722               8310.0   \n",
       "20          320.336667        543.446944              10460.0   \n",
       "21          439.130000        554.032778               8920.0   \n",
       "22         2176.538611       2076.700278              97510.0   \n",
       "23         2157.780278       1980.803056              77390.0   \n",
       "\n",
       "    weekly_incentive_amt  daily_burn_per_rider  daily_burn_per_ride  \\\n",
       "0                 1130.0             50.714440             8.237227   \n",
       "1                 2180.0             31.846840             4.893603   \n",
       "2                  440.0             69.519481             9.568013   \n",
       "3                    0.0             41.888889             6.905310   \n",
       "4                 2910.0             63.442581             8.847660   \n",
       "5                 3810.0             43.444878             6.031799   \n",
       "6                    0.0             20.633180             7.010909   \n",
       "7                  330.0             27.483245             8.129064   \n",
       "8                 1280.0             31.688596             8.702160   \n",
       "9                  530.0             21.126543             7.102999   \n",
       "10                 730.0             24.502821             8.033088   \n",
       "11                   0.0             18.322375             6.519501   \n",
       "12                   0.0             22.642143             7.554091   \n",
       "13                 580.0             31.037851             8.808944   \n",
       "14                2150.0             42.572487             8.787810   \n",
       "15                1290.0             26.275261             5.808347   \n",
       "16                   0.0             23.894231             7.619652   \n",
       "17                   0.0              7.263403             3.064062   \n",
       "18                1100.0             43.453835             9.115020   \n",
       "19                1500.0             23.563456             5.618727   \n",
       "20                1230.0             38.829685             8.300338   \n",
       "21                1960.0             32.047132             6.599250   \n",
       "22                4560.0            109.178942             9.675930   \n",
       "23                6640.0             89.895603             8.138015   \n",
       "\n",
       "    daily_avg_rpr  \n",
       "0        6.145780  \n",
       "1        6.494475  \n",
       "2        7.321429  \n",
       "3        6.000000  \n",
       "4        7.160677  \n",
       "5        7.174370  \n",
       "6        2.945055  \n",
       "7        3.351064  \n",
       "8        3.631579  \n",
       "9        2.980263  \n",
       "10       3.044586  \n",
       "11       2.810219  \n",
       "12       2.969697  \n",
       "13       3.507042  \n",
       "14       4.815331  \n",
       "15       4.503378  \n",
       "16       3.095238  \n",
       "17       2.264706  \n",
       "18       4.752412  \n",
       "19       4.189802  \n",
       "20       4.640741  \n",
       "21       4.748227  \n",
       "22      11.272931  \n",
       "23      11.045296  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "captain_daily_agg_df = get_captain_daily_level_metrics(\n",
    "    rides_df=captain_rides_df,\n",
    "    login_df=captain_login_hrs_df,\n",
    "    incentive_df=incentive_amt_df,\n",
    "    selectors_df=selectors_df,\n",
    "    rides_rider_field='captain_id',\n",
    "    rides_date_field='order_date',\n",
    "    login_rider_field='captain_id',\n",
    "    login_date_field='logindate',\n",
    "    incentive_rider_field='riderid',\n",
    "    incentive_date_field='yyyymmdd',\n",
    "    selector_rider_field='rider'\n",
    "\n",
    ")\n",
    "\n",
    "print(\n",
    "    '*' * 75, '\\n',\n",
    "    'Week {} captain level aggregate metric: \\n'.format(perf_wk),\n",
    "    captain_daily_agg_df.head()\n",
    ")\n",
    "\n",
    "\n",
    "rider_seg_exp_daily_df = captain_daily_agg_df.copy()\n",
    "agg_fields = [\n",
    "    'dropped_order', 'morning_order', 'afternoon_order',\n",
    "    'evening_night_order', 'mid_night_order', 'morning_duration',\n",
    "    'afternoon_duration', 'evening_duration', 'daily_incentive_amt',\n",
    "    'weekly_incentive_amt',\n",
    "]\n",
    "\n",
    "agg_funcs = ['sum'] * len(agg_fields)\n",
    "\n",
    "grouping_vars = [\n",
    "    'city_name', 'week_num',\n",
    "    'poc_segment', 'experiment_group'\n",
    "]\n",
    "\n",
    "daily_seg_metric_sum_df = compute_aggregated_metrics(\n",
    "    captain_daily_agg_df=rider_seg_exp_daily_df,\n",
    "    grouping_var=grouping_vars,\n",
    "    agg_fields=agg_fields,\n",
    "    agg_funcs=agg_funcs,\n",
    ")\n",
    "\n",
    "\n",
    "daily_incentive_df = compute_aggregated_metrics(\n",
    "    captain_daily_agg_df=rider_seg_exp_daily_df,\n",
    "    grouping_var=['city_name', 'week_num', 'order_date',\n",
    "                  'poc_segment', 'experiment_group'],\n",
    "    agg_fields=['daily_incentive_amt', 'dropped_order', 'captain_id'],\n",
    "    agg_funcs=['sum', 'sum', 'nunique'],\n",
    ")\n",
    "\n",
    "daily_incentive_df['daily_burn_per_rider'] =(\n",
    "    daily_incentive_df['daily_incentive_amt'].astype('int') /\n",
    "    daily_incentive_df['captain_id'].astype('int')\n",
    ")\n",
    "\n",
    "daily_incentive_df['daily_burn_per_ride'] = (\n",
    "    daily_incentive_df['daily_incentive_amt'].astype('int') /\n",
    "    daily_incentive_df['dropped_order'].astype('int')\n",
    ")\n",
    "\n",
    "daily_avg_incentive_df = compute_aggregated_metrics(\n",
    "    captain_daily_agg_df=daily_incentive_df,\n",
    "    grouping_var=grouping_vars,\n",
    "    agg_fields=['daily_burn_per_rider', 'daily_burn_per_ride'],\n",
    "    agg_funcs=['mean', 'mean'],\n",
    ")\n",
    "\n",
    "\n",
    "net_rider_df = compute_aggregated_metrics(\n",
    "    captain_daily_agg_df=rider_seg_exp_daily_df,\n",
    "    grouping_var=grouping_vars,\n",
    "    agg_fields=['captain_id'],\n",
    "    agg_funcs=['nunique'],\n",
    ")\n",
    "\n",
    "\n",
    "daily_rpr_df = compute_aggregated_metrics(\n",
    "    captain_daily_agg_df=rider_seg_exp_daily_df,\n",
    "    grouping_var=['city_name', 'week_num', 'captain_id',\n",
    "                  'poc_segment', 'experiment_group'],\n",
    "    agg_fields=['dropped_order'],\n",
    "    agg_funcs=['mean'],\n",
    ")\n",
    "\n",
    "daily_avg_rpr_df = compute_aggregated_metrics(\n",
    "    captain_daily_agg_df=rider_seg_exp_daily_df,\n",
    "    grouping_var=grouping_vars,\n",
    "    agg_fields=['dropped_order'],\n",
    "    agg_funcs=['mean'],\n",
    ")\n",
    "daily_avg_rpr_df.rename(columns={'dropped_order': 'daily_avg_rpr'}, inplace=True)\n",
    "selector_size_df = compute_aggregated_metrics(\n",
    "    captain_daily_agg_df=selectors_df,\n",
    "    grouping_var=['poc_segment', 'experiment_group'],\n",
    "    agg_fields=['rider'],\n",
    "    agg_funcs=['nunique'],\n",
    ")\n",
    "selector_size_df.rename(columns={'rider': 'selector_size'}, inplace=True)\n",
    "\n",
    "final_metric_df = (\n",
    "    net_rider_df\n",
    "    .merge(\n",
    "        selector_size_df,\n",
    "        on=['poc_segment', 'experiment_group']\n",
    "    )\n",
    "    .merge(daily_seg_metric_sum_df,on=grouping_vars,)\n",
    "    .merge(daily_avg_incentive_df, on=grouping_vars)\n",
    "    .merge(daily_avg_rpr_df, on=grouping_vars)\n",
    ")\n",
    "\n",
    "final_metric_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statistical significance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistical_significance(\n",
    "        df_for_stats, significance_test_on,\n",
    "        experiment_grp_name, ctrl_grp_name,\n",
    "        test_grp_name, two_sided_test=True):\n",
    "\n",
    "    control_group = (\n",
    "        df_for_stats[\n",
    "            df_for_stats[experiment_grp_name] == ctrl_grp_name\n",
    "        ][significance_test_on]\n",
    "    )\n",
    "\n",
    "    test_group = (\n",
    "        df_for_stats[\n",
    "            df_for_stats[experiment_grp_name] == test_grp_name\n",
    "        ][significance_test_on]\n",
    "    )\n",
    "\n",
    "    if two_sided_test == False:\n",
    "        test_output = stats.ttest_ind(control_group, test_group, alternative='less')\n",
    "        alpha = 0.10\n",
    "    else:\n",
    "        test_output = stats.ttest_ind(control_group, test_group)\n",
    "        alpha = 0.05\n",
    "\n",
    "    t_calculated = test_output[0]\n",
    "    p_val = test_output[1]\n",
    "\n",
    "    if p_val > alpha:\n",
    "\n",
    "        print(\n",
    "            \"\"\"\n",
    "            As the p-value {:.4f} is greater than the thersold limit {},\n",
    "            we fail to reject null hypothesis i.e. \n",
    "            There is no differece in the mean between Test and Group\n",
    "            basis {} metric\n",
    "            \"\"\".format(p_val, alpha, significance_test_on)\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"\"\"\n",
    "            As the p-value {:.4f} is greater than the thersold limit {},\n",
    "            we fail to accept null hypothesis i.e. \n",
    "            There is a significant differece in the population mean between Test and Group\n",
    "            basis {} metric\n",
    "            \"\"\".format(p_val, alpha, significance_test_on)\n",
    "        )\n",
    "    \n",
    "    return p_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_for_stats = daily_rpr_df.copy()\n",
    "df_for_stats.rename(columns={'dropped_order': 'daily_rpr'}, inplace=True)\n",
    "df_for_stats.dropna(inplace=True)\n",
    "# print(df_for_stats.head())\n",
    "significance_test_on = ['daily_rpr', 'login_hours', 'dropped_order', 'burn_per_ride']\n",
    "test_grp_name = 'test_poc'\n",
    "control_grp_name = 'control_ride_group'\n",
    "experiment_col_name = 'experiment_group'\n",
    "get_statistical_significance(\n",
    "    df_for_stats=df_for_stats,\n",
    "    significance_test_on=significance_test_on[0],\n",
    "    experiment_grp_name=experiment_col_name,\n",
    "    ctrl_grp_name=control_grp_name,\n",
    "    test_grp_name=test_grp_name,\n",
    "    two_sided_test=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for segment \t: MP_D_MO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: LP_D_LO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: UHP_D_UHO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: LP_D_MO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: HP_D_HO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: LP_D_HO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: MP_D_HO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: HP_D_UHO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: LP_D_UHO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: MP_D_LO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: HP_D_MO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n",
      "Evaluation for segment \t: MP_D_UHO\n",
      "\n",
      "            As the p-value nan is greater than the thersold limit 0.1,\n",
      "            we fail to accept null hypothesis i.e. \n",
      "            There is a significant differece in the population mean between Test and Group\n",
      "            basis daily_rpr metric\n",
      "            \n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "segment_list = df_for_stats[segment_col_name].dropna().unique()\n",
    "significance_df = pd.DataFrame()\n",
    "for segment in segment_list:\n",
    "    print('Evaluation for segment \\t: {}'.format(segment))\n",
    "    temp_df = (\n",
    "        df_for_stats[df_for_stats[segment_col_name] == segment]\n",
    "    )\n",
    "    temp_df.dropna(inplace=True)\n",
    "    p_val = get_statistical_significance(\n",
    "        df_for_stats=temp_df,\n",
    "        significance_test_on=significance_test_on[0],\n",
    "        experiment_grp_name=experiment_col_name,\n",
    "        ctrl_grp_name=control_grp_name,\n",
    "        test_grp_name=test_grp_name,\n",
    "        two_sided_test=False\n",
    "    )\n",
    "    print(p_val)\n",
    "\n",
    "    output_df =pd.DataFrame(data=[[segment, p_val]], columns=[['segment', 'p_value']])\n",
    "    significance_df = pd.concat(\n",
    "        [significance_df, output_df]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = selectors_df.groupby(['poc_segment', 'experiment_group'])['rider'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading last week Hyderabad selector ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobilenumber</th>\n",
       "      <th>simplified_segment</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8897745098</td>\n",
       "      <td>HP_D_HO</td>\n",
       "      <td>dormant_control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9392474250</td>\n",
       "      <td>HP_D_HO</td>\n",
       "      <td>dormant_control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9908336595</td>\n",
       "      <td>HP_D_HO</td>\n",
       "      <td>dormant_control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7993974585</td>\n",
       "      <td>HP_D_HO</td>\n",
       "      <td>dormant_control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8897077231</td>\n",
       "      <td>HP_D_HO</td>\n",
       "      <td>dormant_control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobilenumber simplified_segment           cohort\n",
       "0    8897745098            HP_D_HO  dormant_control\n",
       "1    9392474250            HP_D_HO  dormant_control\n",
       "2    9908336595            HP_D_HO  dormant_control\n",
       "3    7993974585            HP_D_HO  dormant_control\n",
       "4    8897077231            HP_D_HO  dormant_control"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read last week\n",
    "experiment_name = 'selectors_dormant'\n",
    "\n",
    "experiment_selectors_file = (\n",
    "    '{city}_{experiment_name}_wk_{week_num}.csv'\n",
    "    .format(city=city, experiment_name = experiment_name, week_num=perf_wk)\n",
    ")\n",
    "\n",
    "print(\"reading last week {city} selector ...\".format(city=city))\n",
    "selectors_df = pd.read_csv(experiment_selectors_file)\n",
    "selectors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectors_df.head()\n",
    "selectors_df_holdout = pd.read_clipboard()\n",
    "\n",
    "selector_holdout_req = pd.DataFrame()\n",
    "for col in selectors_df_holdout.columns:\n",
    "    temp_df = selectors_df_holdout[:][[col]]\n",
    "    temp_df.dropna(inplace=True)\n",
    "    temp_df = temp_df.astype('int')\n",
    "    temp_df.columns = ['mobilenumber']\n",
    "    temp_df['simplified_segment'] = col\n",
    "    temp_df['cohort'] = 'dormant_holdout'\n",
    "    selector_holdout_req = pd.concat([selector_holdout_req, temp_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors_df_test = pd.read_clipboard()\n",
    "\n",
    "selector_test_req = pd.DataFrame()\n",
    "for col in selectors_df_test.columns:\n",
    "    temp_df = selectors_df_test[:][[col]]\n",
    "    temp_df.dropna(inplace=True)\n",
    "    temp_df = temp_df.astype('int')\n",
    "    temp_df.columns = ['mobilenumber']\n",
    "    temp_df['simplified_segment'] = col\n",
    "    temp_df['cohort'] = 'dormant_test'\n",
    "    selector_test_req = pd.concat([selector_test_req, temp_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_selectors = pd.concat([selector_holdout_req, selector_test_req])\n",
    "final_selectors.to_csv(experiment_selectors_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_agg_df.to_clipboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wow_retention(data, rider_col_name, date_col_name):\n",
    "    \"\"\"\n",
    "    :param data: requires pandas dataframe with rider and ride date as the column\n",
    "    :param return: week on week retention dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    data['year'] = (\n",
    "        pd.to_datetime(data[date_col_name])\n",
    "        .dt.isocalendar().year\n",
    "    )\n",
    "\n",
    "    data['week'] = (\n",
    "        pd.to_datetime(data[date_col_name])\n",
    "        .dt.isocalendar().week\n",
    "    )\n",
    "\n",
    "    data['week'] = data.week.map(\"{:02}\".format)\n",
    "\n",
    "    data['week'] = (\n",
    "        data['year'].astype('str') +\n",
    "        '-' +\n",
    "        data['week'].astype('str')\n",
    "    )\n",
    "\n",
    "    weekly_agg_df = (\n",
    "        data[[rider_col_name, 'week']]\n",
    "        .groupby([rider_col_name, 'week'])\n",
    "        .count()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    week_list = weekly_agg_df['week'].unique()\n",
    "    week_list.sort()\n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    for week_one, week_two in zip(week_list[:-1], week_list[1:]):\n",
    "\n",
    "        week_n1_df = (\n",
    "            weekly_agg_df[\n",
    "                weekly_agg_df['week'] == week_one\n",
    "            ]\n",
    "            .rename(\n",
    "                columns={\n",
    "                    'week': 'week_n1',\n",
    "                    rider_col_name: 'rider_wk_n1'\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "        week_n2_df = (\n",
    "            weekly_agg_df[\n",
    "                weekly_agg_df['week'] == week_two\n",
    "            ]\n",
    "            .rename(\n",
    "                columns={\n",
    "                    'week': 'week_n2',\n",
    "                    rider_col_name: 'rider_wk_n2'\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "        wow_df = (\n",
    "            pd.merge(\n",
    "                left=week_n1_df,\n",
    "                right=week_n2_df,\n",
    "                left_on='rider_wk_n1',\n",
    "                right_on='rider_wk_n2',\n",
    "                how='left'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        temp_df = pd.concat([temp_df, wow_df])\n",
    "\n",
    "    retention_view_df = (\n",
    "        temp_df\n",
    "        .groupby(['week_n1'])\n",
    "        .agg(\n",
    "            week_in=('rider_wk_n1', 'nunique'),\n",
    "            week_next=('rider_wk_n2', 'nunique')\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'week_n1': 'week'})\n",
    "    )\n",
    "\n",
    "    return retention_view_df\n",
    "\n",
    "\n",
    "def get_weekly_cohort_retention(data, date_field_name, user_id_col_name):\n",
    "    \"\"\"\n",
    "    :param data: user level daily dataframe\n",
    "    :param date_field_name: date column name in dataframe\n",
    "    :param user_id_col_name: user id column name in dataframe\n",
    "    :return: a dataframe giving WoW basis user turn up\n",
    "    \"\"\"\n",
    "\n",
    "    data[date_field_name] = pd.to_datetime(data[date_field_name])\n",
    "    \n",
    "    min_ride_date_df = (\n",
    "        data\n",
    "        .groupby([user_id_col_name])\n",
    "        .agg(min_ride_date=(date_field_name, min))\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    min_ride_date_df[\"week\"] = (\n",
    "        min_ride_date_df[\"min_ride_date\"]\n",
    "        .dt.isocalendar().week\n",
    "    )\n",
    "    min_ride_date_df = min_ride_date_df.drop(\"min_ride_date\", axis=1)\n",
    "    number_of_weeks = min_ride_date_df[\"week\"].nunique()\n",
    "    \n",
    "    data[\"week\"] = (\n",
    "        data[date_field_name]\n",
    "        .dt.isocalendar().week\n",
    "    )\n",
    "    \n",
    "    weekly_users_df = (\n",
    "        data\n",
    "        .groupby([\"week\", user_id_col_name])\n",
    "        .agg(occurence=(user_id_col_name, \"count\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    weekly_users_df = weekly_users_df.drop(\"occurence\", axis=1)\n",
    "    \n",
    "\n",
    "    min_week_num = weekly_users_df[\"week\"].min()\n",
    "    for val in range(0, number_of_weeks):\n",
    "        temp_df = (\n",
    "            min_ride_date_df[\n",
    "                min_ride_date_df[\"week\"] == min_week_num + val\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        new_df = pd.merge(\n",
    "            weekly_users_df, temp_df,\n",
    "            left_on=user_id_col_name,\n",
    "            right_on=user_id_col_name,\n",
    "            suffixes=(\"\", '-' + str(min_week_num + val)),\n",
    "            how=\"left\"\n",
    "        )\n",
    "        weekly_users_df = new_df.copy()\n",
    "\n",
    "\n",
    "    week_name_list = [\"week-\" + str(num) for num in range(min_week_num, min_week_num+number_of_weeks+1)]\n",
    "\n",
    "    week_num_list = list(range(min_week_num, min_week_num+number_of_weeks+1))\n",
    "    cohort_df = weekly_users_df.drop(user_id_col_name, axis=1)\n",
    "    cohort_df = (\n",
    "        cohort_df[\n",
    "            cohort_df[\"week\"] <= min_week_num + number_of_weeks-1\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    req_df = (\n",
    "        cohort_df\n",
    "        .groupby(\"week\")\n",
    "        .agg(\"count\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    week_dict = dict(zip(week_num_list, week_name_list))\n",
    "    req_df = (\n",
    "        req_df\n",
    "        .replace({\"week\": week_dict})\n",
    "        .reset_index(drop=True)\n",
    "        .set_index(\"week\")\n",
    "    )\n",
    "    req_df = req_df.transpose()\n",
    "    # cols = list(req_df.columns)\n",
    "    # req_df = req_df[cols].div(req_df[cols].max(axis=0)).multiply(100)\n",
    "\n",
    "    return req_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  city_name  order_date                captain_id  dropped_order\n",
      "0    Jaipur  2022-02-14  5f4bcb0dbe98be0219371fe1             11\n",
      "1    Jaipur  2022-02-14  5ce21f7f377155163cfefd65              4\n",
      "2    Jaipur  2022-02-14  5d42434667ecd618f9ee2a41              7\n",
      "3    Jaipur  2022-02-14  5d4134659f859318d1ef554f              9\n",
      "4    Jaipur  2022-02-14  6197c5ff3f25c33a61e1a94c              3\n",
      "   Unnamed: 0                     rider  mobilenumber simplified_segment  \\\n",
      "0           0  611b40028902097aa651d304    9610122951            HP_D_HO   \n",
      "1           1  5f7c17617d99a7fdaa5b47fc    8949608537            HP_D_HO   \n",
      "2           2  61768f51aec47fa49f978c33    9783183771            HP_D_HO   \n",
      "3           3  60753d7879860e1a27b38986    7414870967            HP_D_HO   \n",
      "4           4  5e200a199a0d23428ae4150a    8741996071            HP_D_HO   \n",
      "\n",
      "       cohort    ride_segment  \\\n",
      "0  control_h1  (-0.001, 20.0]   \n",
      "1  control_h1  (-0.001, 20.0]   \n",
      "2  control_h1  (-0.001, 20.0]   \n",
      "3  control_h1  (-0.001, 20.0]   \n",
      "4  control_h1  (-0.001, 20.0]   \n",
      "\n",
      "                                       strat_buckets   shift  \\\n",
      "0  HP_D_HO_(-0.001, 20.0]_(-0.001, 11.667]_(-0.00...  JAI_CM   \n",
      "1  HP_D_HO_(-0.001, 20.0]_(-0.001, 11.667]_(-0.00...  JAI_CM   \n",
      "2  HP_D_HO_(-0.001, 20.0]_(-0.001, 11.667]_(18.33...  JAI_CM   \n",
      "3  HP_D_HO_(-0.001, 20.0]_(-0.001, 11.667]_(18.33...  JAI_CM   \n",
      "4  HP_D_HO_(-0.001, 20.0]_(11.667, 277.0]_(-0.001...  JAI_CM   \n",
      "\n",
      "   mobilenumber_prev  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "3                NaN  \n",
      "4                NaN  \n"
     ]
    }
   ],
   "source": [
    "week_7_df = pd.read_csv('Jaipur_captain_rides_df_wk_07.csv')\n",
    "week_8_df = pd.read_csv('Jaipur_captain_rides_df_wk_08.csv')\n",
    "week_9_df = pd.read_csv('Jaipur_captain_rides_df_wk_09.csv')\n",
    "week_10_df = pd.read_csv('Jaipur_captain_rides_df_wk_10.csv')\n",
    "week_11_df = pd.read_csv('Jaipur_captain_rides_df_wk_11.csv')\n",
    "\n",
    "final_df = pd.concat(\n",
    "    [\n",
    "        week_7_df, week_8_df,\n",
    "        week_9_df, week_10_df,\n",
    "        week_11_df\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(final_df.head())\n",
    "\n",
    "latest_selector_df = pd.read_csv('jaipur_iallocator_experiment_selectors_wk_09.csv')\n",
    "print(latest_selector_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>order_date</th>\n",
       "      <th>captain_id</th>\n",
       "      <th>dropped_order</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rider</th>\n",
       "      <th>mobilenumber</th>\n",
       "      <th>simplified_segment</th>\n",
       "      <th>cohort</th>\n",
       "      <th>ride_segment</th>\n",
       "      <th>strat_buckets</th>\n",
       "      <th>shift</th>\n",
       "      <th>mobilenumber_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>11</td>\n",
       "      <td>2355</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>7023806594</td>\n",
       "      <td>MP_D_LO</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>(20.0, 40.0]</td>\n",
       "      <td>MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...</td>\n",
       "      <td>JAI_CM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>3</td>\n",
       "      <td>2355</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>7023806594</td>\n",
       "      <td>MP_D_LO</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>(20.0, 40.0]</td>\n",
       "      <td>MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...</td>\n",
       "      <td>JAI_CM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2022-02-20</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>5</td>\n",
       "      <td>2355</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>7023806594</td>\n",
       "      <td>MP_D_LO</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>(20.0, 40.0]</td>\n",
       "      <td>MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...</td>\n",
       "      <td>JAI_CM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>9</td>\n",
       "      <td>2355</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>7023806594</td>\n",
       "      <td>MP_D_LO</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>(20.0, 40.0]</td>\n",
       "      <td>MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...</td>\n",
       "      <td>JAI_CM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>5</td>\n",
       "      <td>2355</td>\n",
       "      <td>5f4bcb0dbe98be0219371fe1</td>\n",
       "      <td>7023806594</td>\n",
       "      <td>MP_D_LO</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>(20.0, 40.0]</td>\n",
       "      <td>MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...</td>\n",
       "      <td>JAI_CM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_name  order_date                captain_id  dropped_order  Unnamed: 0  \\\n",
       "0    Jaipur  2022-02-14  5f4bcb0dbe98be0219371fe1             11        2355   \n",
       "1    Jaipur  2022-02-16  5f4bcb0dbe98be0219371fe1              3        2355   \n",
       "2    Jaipur  2022-02-20  5f4bcb0dbe98be0219371fe1              5        2355   \n",
       "3    Jaipur  2022-02-23  5f4bcb0dbe98be0219371fe1              9        2355   \n",
       "4    Jaipur  2022-02-25  5f4bcb0dbe98be0219371fe1              5        2355   \n",
       "\n",
       "                      rider  mobilenumber simplified_segment      cohort  \\\n",
       "0  5f4bcb0dbe98be0219371fe1    7023806594            MP_D_LO  control_h1   \n",
       "1  5f4bcb0dbe98be0219371fe1    7023806594            MP_D_LO  control_h1   \n",
       "2  5f4bcb0dbe98be0219371fe1    7023806594            MP_D_LO  control_h1   \n",
       "3  5f4bcb0dbe98be0219371fe1    7023806594            MP_D_LO  control_h1   \n",
       "4  5f4bcb0dbe98be0219371fe1    7023806594            MP_D_LO  control_h1   \n",
       "\n",
       "   ride_segment                                      strat_buckets   shift  \\\n",
       "0  (20.0, 40.0]  MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...  JAI_CM   \n",
       "1  (20.0, 40.0]  MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...  JAI_CM   \n",
       "2  (20.0, 40.0]  MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...  JAI_CM   \n",
       "3  (20.0, 40.0]  MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...  JAI_CM   \n",
       "4  (20.0, 40.0]  MP_D_LO_(20.0, 40.0]_(11.667, 277.0]_(18.333, ...  JAI_CM   \n",
       "\n",
       "   mobilenumber_prev  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# city retention number\n",
    "req_retention_df = (\n",
    "    final_df\n",
    "    .merge(\n",
    "        latest_selector_df,\n",
    "        left_on=['captain_id'],\n",
    "        right_on=['rider'],\n",
    "        how='inner'\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "req_retention_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>week_in</th>\n",
       "      <th>week_next</th>\n",
       "      <th>experiment_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07</td>\n",
       "      <td>3028</td>\n",
       "      <td>2421</td>\n",
       "      <td>control_h1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08</td>\n",
       "      <td>2885</td>\n",
       "      <td>2215</td>\n",
       "      <td>control_h1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09</td>\n",
       "      <td>2510</td>\n",
       "      <td>2060</td>\n",
       "      <td>control_h1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>2460</td>\n",
       "      <td>1871</td>\n",
       "      <td>control_h1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07</td>\n",
       "      <td>3156</td>\n",
       "      <td>2521</td>\n",
       "      <td>test_h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08</td>\n",
       "      <td>3023</td>\n",
       "      <td>2328</td>\n",
       "      <td>test_h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09</td>\n",
       "      <td>2644</td>\n",
       "      <td>2151</td>\n",
       "      <td>test_h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>2562</td>\n",
       "      <td>1939</td>\n",
       "      <td>test_h2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      week  week_in  week_next experiment_name\n",
       "0  2022-07     3028       2421      control_h1\n",
       "1  2022-08     2885       2215      control_h1\n",
       "2  2022-09     2510       2060      control_h1\n",
       "3  2022-10     2460       1871      control_h1\n",
       "0  2022-07     3156       2521         test_h2\n",
       "1  2022-08     3023       2328         test_h2\n",
       "2  2022-09     2644       2151         test_h2\n",
       "3  2022-10     2562       1939         test_h2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expmnt_wow_reten_df = pd.DataFrame()\n",
    "\n",
    "for val in req_retention_df.cohort.unique():\n",
    "    temp_df = req_retention_df[\n",
    "        req_retention_df['cohort'] == val\n",
    "    ].reset_index()\n",
    "\n",
    "    retention_df = get_wow_retention(\n",
    "        data=temp_df,\n",
    "        rider_col_name='captain_id',\n",
    "        date_col_name='order_date'\n",
    "    )\n",
    "    \n",
    "    retention_df.loc[:, 'experiment_name'] = val\n",
    "\n",
    "    expmnt_wow_reten_df = pd.concat(\n",
    "        [expmnt_wow_reten_df, retention_df]\n",
    "    )\n",
    "\n",
    "expmnt_wow_reten_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>week_in</th>\n",
       "      <th>week_next</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>MP_D_LO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>MP_D_LO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>MP_D_LO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>MP_D_LO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07</td>\n",
       "      <td>411</td>\n",
       "      <td>331</td>\n",
       "      <td>control_h1</td>\n",
       "      <td>LP_D_MO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      week  week_in  week_next experiment_name  segment\n",
       "0  2022-07       22         17      control_h1  MP_D_LO\n",
       "1  2022-08       21         16      control_h1  MP_D_LO\n",
       "2  2022-09       19         16      control_h1  MP_D_LO\n",
       "3  2022-10       21         17      control_h1  MP_D_LO\n",
       "0  2022-07      411        331      control_h1  LP_D_MO"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "expmnt_seg_wow_reten_df = pd.DataFrame()\n",
    "cohort_group_list = req_retention_df.cohort.unique()\n",
    "segment_list = req_retention_df.simplified_segment.unique()\n",
    "for group in cohort_group_list:\n",
    "    for segment in segment_list:\n",
    "        temp_df = req_retention_df[\n",
    "            (req_retention_df['cohort'] == group) &\n",
    "            (req_retention_df['simplified_segment'] == segment)\n",
    "        ].reset_index()\n",
    "\n",
    "        retention_df = get_wow_retention(\n",
    "            data=temp_df,\n",
    "            rider_col_name='captain_id',\n",
    "            date_col_name='order_date'\n",
    "        )\n",
    "\n",
    "        retention_df.loc[:, 'experiment_name'] = group\n",
    "        retention_df.loc[:, 'segment'] = segment\n",
    "\n",
    "        expmnt_seg_wow_reten_df = pd.concat(\n",
    "            [expmnt_seg_wow_reten_df, retention_df]\n",
    "        )\n",
    "\n",
    "expmnt_seg_wow_reten_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "expmnt_seg_wow_reten_df.to_clipboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get cohort retention for each group\n",
    "experiment_groups = req_retention_df['cohort'].unique()\n",
    "city_cohort_retention_df = pd.DataFrame()\n",
    "seg_cohort_retention_df = pd.DataFrame()\n",
    "segment_list = req_retention_df['simplified_segment'].unique()\n",
    "for exp_grp_name in experiment_groups:\n",
    "    for segment in segment_list:    \n",
    "        temp_df = (\n",
    "            req_retention_df[\n",
    "                (req_retention_df['cohort'] == exp_grp_name) &\n",
    "                (req_retention_df['simplified_segment'] == segment)\n",
    "            ]\n",
    "        ).reset_index()\n",
    "\n",
    "        temp_retention_df = get_weekly_cohort_retention(\n",
    "            temp_df, 'order_date', 'captain_id'\n",
    "        )\n",
    "        temp_retention_df.insert(0, 'experiment_group', exp_grp_name)\n",
    "        temp_retention_df.insert(1, 'segment', segment)\n",
    "\n",
    "        seg_cohort_retention_df = pd.concat(\n",
    "            [seg_cohort_retention_df, temp_retention_df]\n",
    "        )\n",
    "\n",
    "for exp_grp_name in experiment_groups:\n",
    "    temp_df = (\n",
    "        req_retention_df[\n",
    "            (req_retention_df['cohort'] == exp_grp_name)\n",
    "        ]\n",
    "    ).reset_index()\n",
    "    temp_retention_df = get_weekly_cohort_retention(\n",
    "    temp_df, 'order_date', 'captain_id'\n",
    "    )\n",
    "    temp_retention_df.insert(0, 'experiment_group', exp_grp_name)\n",
    "    temp_retention_df.insert(1, 'segment', 'city')\n",
    "    city_cohort_retention_df = pd.concat(\n",
    "        [city_cohort_retention_df, temp_retention_df]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>week</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>segment</th>\n",
       "      <th>week-7</th>\n",
       "      <th>week-8</th>\n",
       "      <th>week-9</th>\n",
       "      <th>week-10</th>\n",
       "      <th>week-11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>week-7</th>\n",
       "      <td>control_h1</td>\n",
       "      <td>city</td>\n",
       "      <td>3028</td>\n",
       "      <td>2421</td>\n",
       "      <td>2122</td>\n",
       "      <td>2040</td>\n",
       "      <td>1780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week-8</th>\n",
       "      <td>control_h1</td>\n",
       "      <td>city</td>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>271</td>\n",
       "      <td>253</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week-9</th>\n",
       "      <td>control_h1</td>\n",
       "      <td>city</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>83</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week-10</th>\n",
       "      <td>control_h1</td>\n",
       "      <td>city</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week-11</th>\n",
       "      <td>control_h1</td>\n",
       "      <td>city</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week-7</th>\n",
       "      <td>test_h2</td>\n",
       "      <td>city</td>\n",
       "      <td>3156</td>\n",
       "      <td>2521</td>\n",
       "      <td>2204</td>\n",
       "      <td>2162</td>\n",
       "      <td>1847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week-8</th>\n",
       "      <td>test_h2</td>\n",
       "      <td>city</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>308</td>\n",
       "      <td>276</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week-9</th>\n",
       "      <td>test_h2</td>\n",
       "      <td>city</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week-10</th>\n",
       "      <td>test_h2</td>\n",
       "      <td>city</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week-11</th>\n",
       "      <td>test_h2</td>\n",
       "      <td>city</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "week    experiment_group segment  week-7  week-8  week-9  week-10  week-11\n",
       "week-7        control_h1    city    3028    2421    2122     2040     1780\n",
       "week-8        control_h1    city       0     464     271      253      210\n",
       "week-9        control_h1    city       0       0     117       83       64\n",
       "week-10       control_h1    city       0       0       0       84       44\n",
       "week-11       control_h1    city       0       0       0        0       31\n",
       "week-7           test_h2    city    3156    2521    2204     2162     1847\n",
       "week-8           test_h2    city       0     502     308      276      240\n",
       "week-9           test_h2    city       0       0     132       69       56\n",
       "week-10          test_h2    city       0       0       0       55       30\n",
       "week-11          test_h2    city       0       0       0        0       31"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seg_cohort_retention_df.to_clipboard()\n",
    "city_cohort_retention_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_cohort_retention_df.to_clipboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Selectors Framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prerequisite\n",
    "- period to consider 28 days (4 rolling weeks)\n",
    "- segment to consider latest\n",
    "- order, login hours, incentive, total earnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file = os.listdir(\"/Users/rapido/Dharmendra/Photos/finalized_pics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352500.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1410000 * .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2022-05-30', '2022-06-05')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_start_end_date_from_week(22, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  =pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poc_segment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobilenumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ride_group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>daily_incentive_bucket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>daily_earnings_bucket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>daily_lh_bucket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekly_incentive_bucket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>experiment_group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "0                     city\n",
       "1                    rider\n",
       "2              poc_segment\n",
       "3             mobilenumber\n",
       "4               ride_group\n",
       "5   daily_incentive_bucket\n",
       "6    daily_earnings_bucket\n",
       "7          daily_lh_bucket\n",
       "8  weekly_incentive_bucket\n",
       "9         experiment_group"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
